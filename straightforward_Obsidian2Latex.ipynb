{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Tasks\n",
    "\n",
    "- ➕ Need to add the LateX command \"\\newline\" after equations that start with single \"$\"\n",
    "    - Even better: add same command before the equation, but twice\n",
    "        - HOWEVER, this problem would not be triggered if the author writes the equations with double \"$\"s\n",
    "- ➕ remove markdown comments from embedded files\n",
    "- ➕ Embedded refs, when a certain section is referenced: Need to change the hierarchy of potential \"inner sections\"\n",
    "- ➕ non-embedded external links --> remove Markdown linking format and add selection in the settings for the user to choose if they want to convert that reference to pdf as well and create hyperlink in the original pdf to that pdf\n",
    "\n",
    "- ➕ section recognition from embedded notes does not work (test with \"Assignment--11.md\" and see \"# Embedded-Section-Error\" comment in \"embedded_notes.py\")\n",
    "- ➕⚠ with the \"kernel trick.md\" example, the inner references do not work!!\n",
    "\n",
    "## Math-related\n",
    "- ➕ \"\\cancel\" function does not work\n",
    "\n",
    "- ⚠ When parentheses are part of the reference note name, the regex recognition fails\n",
    "## Edge cases\n",
    "- ➕ Consider case wherein there's more than one sections with the same name\n",
    "\n",
    "\n",
    "For the markdown comment removal, use for testing:\n",
    "- [[p514--notes]]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "## Prerequisites\n",
    "1. Have Python 3 installed\n",
    "\n",
    "\n",
    "\n",
    "## Usage\n",
    "For each user-defined parameter, go to the [User Parameters](#user-parameters) section, wherein the 'PARS' dictionary is located.\n",
    "\n",
    "To set the paths for the .md file to be converted, change the `PARS['📂']['markdown-file']` and `PARS['📂']['tex-file']`.\n",
    "Then, just run all code blocks and VOILA!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from remove_markdown_comment import *\n",
    "from symbol_replacements import *\n",
    "from embedded_notes import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dict(D):\n",
    "    for key in D.keys():\n",
    "        if D[key] == '🟢':\n",
    "            D[key] = True\n",
    "        elif D[key] == '🔴':\n",
    "            D[key] = False\n",
    "    return D\n",
    "\n",
    "\n",
    "# is_in_table_line = lambda x: x.startswith('|') and x.endswith('|')\n",
    "# enum             = lambda x: enumerate(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants (to not be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID__TABLES__alignment__center = 0\n",
    "ID__TABLES__alignment__right  = 1\n",
    "ID__TABLES__alignment__middle = 2\n",
    "\n",
    "\n",
    "ID__TABLES__PACKAGE__longtblr = 0\n",
    "ID__TABLES__PACKAGE__tabularx = 1\n",
    "\n",
    "ID__CNV__TABLE_STARTED      = 0\n",
    "ID__CNV__TABLE_ENDED        = 1\n",
    "ID__CNV__IDENTICAL          = 2\n",
    "\n",
    "# ⚠ does not work for longtblr!\n",
    "CMD__TABLE__TABULARX__CENTERING = '\\\\newcolumntype{Y}{>{\\\\centering\\\\arraybackslash}X}'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files  = 'C:\\\\Users\\\\mariosg\\\\OneDrive - NTNU\\\\FILES\\\\workTips\\\\'\n",
    "path0       = path_files + 'AUTOMATIONS\\\\'\n",
    "path_file = path_files+'Literature\\\\Theory\\\\Methods\\\\in Machine Learning\\\\kernel trick'\n",
    "\n",
    "PARS = conv_dict(dict({\n",
    "    '⚙': # SETTINGS\n",
    "        conv_dict(dict({'TABLES':  \n",
    "                conv_dict(dict({\n",
    "                                                  'package': ID__TABLES__PACKAGE__longtblr,\n",
    "                                       'hlines-to-all-rows': '🔴',\n",
    "                                        'any-hlines-at-all': '🔴',\n",
    "                                                'alignment': [\n",
    "                                                                ID__TABLES__alignment__center,\n",
    "                                                                ID__TABLES__alignment__middle],\n",
    "                                                'rel-width': 1.2\n",
    "                })),\n",
    "                      'margin': '0.9in',\n",
    "                  'EXCEPTIONS': \n",
    "                                conv_dict(dict({\n",
    "                                    'raise_exception__when__embedded_reference_not_found': '🔴'\n",
    "                                    }))\n",
    "                      })),\n",
    "    '📁':\n",
    "         dict({\n",
    "                'markdown-file': path_file+'.md',  # Markdown (.md) file for conversion\n",
    "                     'tex-file': path_file+'.tex',  # LateX (.tex) file (converted from the .md file)\n",
    "                        'vault': path_files\n",
    "            }),\n",
    "    'par':\n",
    "        dict({\n",
    "            'tabular-package':\n",
    "                            dict({\n",
    "                                       'names': ['longtblr', 'tabularx'],\n",
    "                                'before-lines': ['{colspec}']\n",
    "                            }),\n",
    "            'packages-to-load':[                    # Which packages to load on the LateX preable\n",
    "                                'hyperref',\n",
    "                                'graphicx',\n",
    "                                'amssymb',           # need more symbols\n",
    "                                'titlesec',          # so that we can add more subsections (using 'paragraph')\n",
    "                                'xcolor',\n",
    "                                'amsmath',\n",
    "                                'amsfonts'\n",
    "                                ],\n",
    "          'symbols-to-replace': [       # Obsidian symbol, latex symbol,            type of replacement (1 or 2)\n",
    "                                        ['✔',              '\\\\checkmark',            1],\n",
    "                                        ['🟢',              '$\\\\\\\\blacklozenge$',    2],\n",
    "                                        ['🔴',              '\\\\\\maltese',            2],\n",
    "                                        ['➕',              '\\\\boxplus',             2],\n",
    "                                        ['🔗',              'LINK',                  1],\n",
    "                                        ['\\implies',        '\\Rightarrow',            1],\n",
    "                                        ['❓',              '?',                      1],\n",
    "                                        ['❌',              'NO',                     1],\n",
    "                                        ['\\\\text',          '\\\\textnormal',           1]\n",
    "                                        ]\n",
    "        })\n",
    "}))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_loader():\n",
    "\n",
    "    packages_to_load = PARS['par']['packages-to-load']\n",
    "    tables_package = PARS['⚙']['TABLES']['package']\n",
    "    if tables_package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        packages_to_load.append('tabularray')\n",
    "        packages_to_load.append('longtable')\n",
    "\n",
    "    elif tables_package == ID__TABLES__PACKAGE__tabularx:\n",
    "        packages_to_load.append('tabularx')\n",
    "        \n",
    "\n",
    "    out = ['\\\\usepackage{'+x+'}' for x in packages_to_load]\n",
    "    \n",
    "    page_margin = PARS['⚙']['margin']\n",
    "    if len(page_margin) > 0:\n",
    "        out.append('\\\\usepackage[margin='+ page_margin + ']{geometry}')\n",
    " \n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def replace_hyperlinks(S):\n",
    "    \n",
    "\n",
    "    # Anything that isn't a square closing bracket\n",
    "    name_regex = \"[^]]+\"\n",
    "    # http:// or https:// followed by anything but a closing paren\n",
    "    url_regex = \"http[s]?://[^)]+\"\n",
    "\n",
    "    markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "\n",
    "    S_1 = []\n",
    "    for s in S:\n",
    "        s1 = s \n",
    "\n",
    "        for match in re.findall(markup_regex, s1):\n",
    "            markdown_link = '[' + match[0] + '](' + match[1] + ')'\n",
    "            latex_link = \"\\\\href{\" + match[1] + \"}{\" + match[0] + \"}\"\n",
    "            s1 = s1.replace(markdown_link, latex_link)\n",
    "\n",
    "        S_1.append(s1)\n",
    "    \n",
    "    return S_1\n",
    "\n",
    "def identify__tables(S):\n",
    "\n",
    "    table_indexes = []\n",
    "    table_has_started = False\n",
    "    for i, l in enum(S):\n",
    "        lstr = l.lstrip().rstrip()\n",
    "        is_table_line = is_in_table_line(lstr)        \n",
    "        if is_table_line and (not table_has_started):\n",
    "            table_has_started = True\n",
    "            idx__table_start = i\n",
    "        # ⚠ NEVER add \"or (i == len(S)-1)\" to the condition below    \n",
    "        elif (not is_table_line and table_has_started):\n",
    "            table_has_started = False\n",
    "            idx__table_end = i\n",
    "            table_indexes.append(idx__table_start)\n",
    "            table_indexes.append(idx__table_end)\n",
    "\n",
    "\n",
    "    return table_indexes\n",
    "\n",
    "\n",
    "def bold_font(S):\n",
    "    '''\n",
    "    Converts bold font\n",
    "    '''\n",
    "    S1 = []\n",
    "    for s in S:\n",
    "        occurences = [x.start() for x in re.finditer('\\*\\*', s)]\n",
    "        L = len(occurences)\n",
    "\n",
    "        if L % 2 == 0:\n",
    "            replacements = []\n",
    "            for i in range(int(L/2)):\n",
    "                o0 = occurences[2*i]\n",
    "                o1 = occurences[2*i+1]\n",
    "                replacements.append(['**'+s[o0+2:o1]+'**', '\\\\textbf{' + s[o0+2:o1] + '}'])\n",
    "                \n",
    "            for R in replacements:\n",
    "                s = s.replace(R[0], R[1])\n",
    "        else:\n",
    "            raise Exception(\"error for this case, for now\")\n",
    "        \n",
    "        S1.append(s)\n",
    "    \n",
    "    return S1\n",
    "\n",
    " \n",
    "def convert__tables(S):\n",
    "    '''\n",
    "    Converts tables depending on the user's preferences    \n",
    "    '''\n",
    "\n",
    "    TABLE_SETTINGS = PARS['⚙']['TABLES']\n",
    "    package = TABLE_SETTINGS['package']\n",
    "    add_txt = ''\n",
    "    if (ID__TABLES__alignment__center in TABLE_SETTINGS['alignment']) \\\n",
    "        and package == ID__TABLES__PACKAGE__longtblr:\n",
    "        add_txt = '\\centering '\n",
    "\n",
    "\n",
    "    # After having found the table\n",
    "    ## We expect that the 1st line defines the columns\n",
    "\n",
    "    cols = S[0].split('|')\n",
    "    cols = [[x.lstrip().rstrip() for x in cols if len(x)>0 and x!='\\n']]\n",
    "\n",
    "    C = []\n",
    "    for s in S[2:]:\n",
    "        c = s.split('|')\n",
    "        c = [x.lstrip().rstrip() for x in c if len(x)>0 and x!='\\n']\n",
    "        C.append(c)\n",
    "\n",
    "    y = cols + C\n",
    "\n",
    "    # CONVERT\n",
    "    N_cols = len(cols[0])\n",
    "\n",
    "    latex_table = []\n",
    "    addText = ''\n",
    "    for i, c in enum(y):\n",
    "        c1 = [add_txt + x for x in c]\n",
    "        if i==0: \n",
    "            if TABLE_SETTINGS['any-hlines-at-all']:\n",
    "                addText = ' \\hline'\n",
    "        else:\n",
    "            if TABLE_SETTINGS['hlines-to-all-rows']:\n",
    "                addText = ' \\hline'\n",
    "        latex_table.append('    ' + \" & \".join(c1) + ' \\\\\\\\' + addText)\n",
    "\n",
    "    lbefore = []\n",
    "\n",
    "\n",
    "    if package == ID__TABLES__PACKAGE__tabularx:\n",
    "\n",
    "\n",
    "        PCKG_NAME = '{tabularx}'\n",
    "\n",
    "        if ID__TABLES__alignment__center in TABLE_SETTINGS['alignment']:\n",
    "            lbefore.append(CMD__TABLE__TABULARX__CENTERING)\n",
    "            colPrefix = 'Y'\n",
    "        else:\n",
    "            colPrefix = 'X'\n",
    "\n",
    "        if (ID__TABLES__alignment__middle in TABLE_SETTINGS['alignment']):\n",
    "            lbefore.append('\\\\renewcommand\\\\tabularxcolumn[1]{m{#1}}')\n",
    "\n",
    "        latex_before_table = lbefore + [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin'+PCKG_NAME+'{\\\\textwidth}{' + '|' + N_cols*(colPrefix+'|') + '}',\n",
    "            '   \\hline'\n",
    "        ]\n",
    "\n",
    "        latex_after_table = [\n",
    "            '   \\hline',\n",
    "            '\\end'+PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "    elif package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        PCKG_NAME = '{longtblr}'\n",
    "\n",
    "        latex_before_table = [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin' + PCKG_NAME + '[',\n",
    "            'caption = {},',\n",
    "            'entry = {},',\n",
    "            'label = {},',\n",
    "            'note{a} = {},',\n",
    "            'note{$\\dag$} = {}]',\n",
    "            '   {colspec = {'+ N_cols*'X' +'}, width = ' + str(TABLE_SETTINGS['rel-width']) + '\\linewidth, hlines, rowhead = 2, rowfoot = 1}'\n",
    "            ]  \n",
    "\n",
    "        latex_after_table = [\n",
    "            '\\end' + PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        add_hline_at_end = False # to be moved to user settings\n",
    "        if add_hline_at_end:\n",
    "            latex_after_table = '   \\hline' + latex_after_table\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "\n",
    "\n",
    "    LATEX = latex_before_table + latex_table + latex_after_table\n",
    "\n",
    "\n",
    "    return LATEX\n",
    "\n",
    "\n",
    "def images_converter(images):\n",
    "\n",
    "    '''\n",
    "    Converts Images given the path of the image file\n",
    "    '''\n",
    "\n",
    "    # NOTES:\n",
    "    # --- \", height=0.5\\\\textheight\" addition causes the aspect ratio to break\n",
    "\n",
    "    TO_PRINT = []\n",
    "\n",
    "    for IM in images:\n",
    "        path_img = '\"' + IM[1].replace('\\\\', '/') + '\"'\n",
    "        label_img = IM[1].split('\\\\')[-1]\n",
    "        caption_short = 'Caption short'\n",
    "        caption_long = 'Caption long'\n",
    "\n",
    "        TO_PRINT.append(' \\n'.join([\n",
    "        '\\\\begin{figure}',\n",
    "        '\t\\centering',\n",
    "        '\t\\includegraphics[width=0.7\\linewidth]'+\\\n",
    "            '{\"'+path_img+'\"}',\n",
    "        '\t\\caption['+caption_short+']{'+caption_long+'}',\n",
    "        '\t\\label{fig:'+label_img+'}',\n",
    "        '\\end{figure}']))\n",
    "\n",
    "    return TO_PRINT\n",
    "\n",
    "\n",
    "def bullet_list_converter(S):\n",
    "\n",
    "    S = ''.join(S)\n",
    "\n",
    "    latex = \"\"\n",
    "    lines = S.split(\"\\n\")\n",
    "    indent = 0\n",
    "    intent_list_type = []\n",
    "    # tab_1 = \" \"*4\n",
    "    tab_1 = \"\\t\"\n",
    "    Lt = len(tab_1)\n",
    "    beg_item = \"\\\\begin{itemize}\\n\"\n",
    "    beg_enum = \"\\\\begin{enumerate}\\n\"\n",
    "\n",
    "    end_type = [\"\\\\end{itemize}\\n\", \"\\\\end{enumerate}\\n\"]\n",
    "\n",
    "    first_itemize = False\n",
    "    number_list = 1\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(tab_1* indent + \"- \") or line.startswith(tab_1* indent + \"* \"):\n",
    "            \n",
    "            intent_list_type.append([indent, 0])\n",
    "            if not first_itemize: \n",
    "                first_itemize = True\n",
    "                list_closed = False\n",
    "                beg_item_i = beg_item\n",
    "                Li = 1\n",
    "            else:\n",
    "                beg_item_i = \"\"\n",
    "                Li = 1\n",
    "            latex += tab_1* (indent)*(len(beg_item_i)>0) + beg_item_i +  tab_1* (indent+1) + \"\\\\item \" + line[2 + indent*Lt:].strip() + \"\\n\"\n",
    "        elif line.startswith(tab_1* (indent + 1) + \"- \") or line.startswith(tab_1* (indent + 1) + \"* \"):\n",
    "            latex += tab_1 * (indent+1) + beg_item\n",
    "            indent += 1\n",
    "            intent_list_type.append([indent, 0])\n",
    "            latex += tab_1 * (indent+1) + \"\\\\item \" + line[2 + (indent+0)*Lt:].strip() + \"\\n\"\n",
    "        elif line.startswith(tab_1* (indent - 1) + \"- \") or line.startswith(tab_1* (indent - 1) + \"* \") and indent > 0:\n",
    "            indent -= 1\n",
    "            intent_list_type.append([indent, 0])\n",
    "            latex += tab_1 * indent + \"\\\\end{itemize}\\n\"\n",
    "            latex += tab_1 * indent + \"\\\\item \" + line[2 + (indent-1)*Lt:].strip() + \"\\n\"\n",
    "        \n",
    "        elif line.startswith(tab_1* (indent - 2) + \"- \") or line.startswith(tab_1* (indent - 2) + \"* \") and indent > 0:\n",
    "            # UNDER DEV ---> need to close previous lists\n",
    "            indent -= 2\n",
    "            intent_list_type.append([indent, 0])\n",
    "            latex += tab_1 * (indent-1) + \"\\\\end{itemize}\\n\"\n",
    "            latex += tab_1 * (indent-1) + \"\\\\item \" + line[2 + (indent-2)*Lt:].strip() + \"\\n\"\n",
    "        \n",
    "        elif line.startswith(tab_1* (indent - 3) + \"- \") or line.startswith(tab_1* (indent - 3) + \"* \") and indent > 0:\n",
    "            \n",
    "            # UNDER DEV ---> need to close previous lists\n",
    "            indent -= 3\n",
    "            intent_list_type.append([indent, 0])\n",
    "            latex += tab_1 * (indent-2) + \"\\\\end{itemize}\\n\"\n",
    "            latex += tab_1 * (indent-2) + \"\\\\item \" + line[2 + (indent-3)*Lt:].strip() + \"\\n\"\n",
    "\n",
    "\n",
    "        elif line.startswith(tab_1* indent + str(number_list) + \". \"):\n",
    "            intent_list_type.append([indent, 1])\n",
    "            latex += tab_1* (indent) +  tab_1* (indent+1) + \"\\\\item \" + line[2 + indent*Lt:].strip() + \"\\n\"\n",
    "            number_list += 1\n",
    "        \n",
    "        elif line.startswith(tab_1* (indent+1) + str(number_list) + \". \"):\n",
    "            latex += tab_1 * (indent+1) + beg_enum\n",
    "            indent += 1\n",
    "            intent_list_type.append([indent, 1])\n",
    "            latex += tab_1 * (indent+1) + \"\\\\item \" + line[2 + (indent+0)*Lt:].strip() + \"\\n\"\n",
    "            number_list += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            while (indent > -1) and first_itemize:\n",
    "                \n",
    "                latex += tab_1 * indent +  end_type[[xx[1] for xx in intent_list_type if xx[0]==indent][0]]  \n",
    "                indent -= 1\n",
    "\n",
    "            latex += line + \"\\n\"\n",
    "            first_itemize = False\n",
    "            list_closed = True\n",
    "            indent = 0\n",
    "            number_list = 1\n",
    "            intent_list_type = []\n",
    "\n",
    "\n",
    "    if not list_closed: \n",
    "        # in case that the Lines end abruptly before getting the chance to close the list (rare)\n",
    "        while (indent > -1) and first_itemize:\n",
    "            \n",
    "            latex += tab_1 * indent + end_type[intent_list_type[indent][0]]\n",
    "            indent -= 1\n",
    "\n",
    "    return latex.split(\"\\n\")\n",
    "\n",
    "\n",
    "def add_new_line_equations(S0):\n",
    "\n",
    "\n",
    "    # This function assumes that the '\\n' symbol hasn't been added yet\n",
    "\n",
    "    S = S0\n",
    "    for i, s in enum(S):\n",
    "\n",
    "        if not s.endswith('$$') and s.endswith('$'):\n",
    "            if i<len(S):\n",
    "                S[i+1] = '\\n' + S[i+1]\n",
    "\n",
    "        if not s.startswith('$$') and s.startswith('$'):\n",
    "            if i>0: \n",
    "                if not S[i-1].endswith('\\n'):\n",
    "                    S[i-1] = S[i-1] + '\\n'*2\n",
    "                else:\n",
    "                    S[i-1] = S[i-1] + '\\n'\n",
    "\n",
    "        # if not s.endswith('$$') and s.endswith('$'):\n",
    "        #     if i<len(S):\n",
    "\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "PATHS = PARS['📁']\n",
    "\n",
    "with open(PATHS['markdown-file'], 'r', encoding='utf8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "\n",
    "content = remove_markdown_comments(content)\n",
    "\n",
    "# UNFOLD EMBEDDED NOTES ============================================================================================================================================\n",
    "md__files_embedded_prev0 = []\n",
    "md__files_embedded_prev = md__files_embedded_prev0.copy()\n",
    "[content, md__files_embedded_new] = unfold_embedded_notes(content, md__files_embedded_prev, PARS)\n",
    "\n",
    "while md__files_embedded_prev0 != md__files_embedded_new:\n",
    "    md__files_embedded_prev0 = md__files_embedded_new.copy()\n",
    "    md__files_embedded_prev = md__files_embedded_prev0.copy()\n",
    "    [content, md__files_embedded_new] = unfold_embedded_notes(content, md__files_embedded_prev, PARS)\n",
    "\n",
    "# ======================================================================================================================================================================\n",
    "\n",
    "# Convert bullet and numbered lists.\n",
    "\n",
    "content = bullet_list_converter(content)\n",
    "\n",
    "\n",
    "# Replace headers and map sections \\==================================================\n",
    "Lc = len(content)-1\n",
    "sections = []\n",
    "for i in range(Lc+1):\n",
    "    # ⚠ The sequence of replacements matters: \n",
    "    # ---- replace the lowest-level subsections first\n",
    "    content_00 = content[i]\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'#### (.*)', r'\\\\paragraph{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('#### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'### (.*)', r'\\\\subsubsection{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'## (.*)', r'\\\\subsection{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('## ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'# (.*)', r'\\\\section{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('# ', '').replace('\\n', '')])\n",
    "\n",
    "# \\==================================================\\==================================================\n",
    "\n",
    "# find reference blocks \\==================================================\n",
    "#---1. they have to be at the end of the sentence (i.e. before \"\\n\")\n",
    "blocks = []\n",
    "for i in range(Lc+1):\n",
    "    s = content[i].replace('\\n', '')\n",
    "    pattern = r\"\\^[\\w\\-]*$\"\n",
    "    link_label = re.findall(pattern, s)\n",
    "    if len(link_label) > 0:\n",
    "        blocks.append([i, link_label[0].replace('^', '')])    \n",
    "# \\==================================================\n",
    "\n",
    "# Find and apply internal links\n",
    "internal_links = internal_links__identifier(content)\n",
    "content = internal_links__enforcer(content, [sections, blocks], internal_links)\n",
    "#\n",
    "\n",
    "# Convert figures \\==================================================\n",
    "\n",
    "embeded_refs = embedded_references_recognizer(content)\n",
    "\n",
    "# ➕ add more image refs\n",
    "# replace \"content[line_number]\" accordingly and see the result\n",
    "\n",
    "for i, ln in enum(embeded_refs):\n",
    "\n",
    "    line_number = ln[0]\n",
    "    line_refs = ln[1]\n",
    "    for lnrf in line_refs:\n",
    "\n",
    "        # print(embedded_references_path_finder(lnrf[0]))\n",
    "        converted_image_text = images_converter([[line_number, embedded_references_path_finder(lnrf[0], PARS)]])\n",
    "        \n",
    "        for img_txt_cnv in converted_image_text:\n",
    "            tmp1 = '![[' + lnrf[0]\n",
    "            if ('.png' in lnrf[0] or '.jpg' in lnrf[0]) and (lnrf[1].replace('|','')).isnumeric():\n",
    "                content[line_number] = content[line_number].replace(tmp1 + lnrf[1] + ']]', img_txt_cnv)\n",
    "            else:\n",
    "                content[line_number] = content[line_number].replace(tmp1 + ']]', img_txt_cnv)\n",
    "\n",
    "\n",
    "# \\==================================================\n",
    "content = add_new_line_equations(content)\n",
    "\n",
    "IDX__TABLES = [0]\n",
    "TYPE_OF_CNV = [ID__CNV__IDENTICAL]\n",
    "tmp1 = identify__tables(content)\n",
    "tmp2 = [ID__CNV__TABLE_STARTED for _ in tmp1]\n",
    "tmp2[1::2] = [ID__CNV__IDENTICAL for _ in tmp1[1::2]]\n",
    "IDX__TABLES += tmp1\n",
    "TYPE_OF_CNV += tmp2\n",
    "\n",
    "Lc = len(content)-1\n",
    "if IDX__TABLES[-1] < Lc: \n",
    "    IDX__TABLES.append(Lc)\n",
    "    TYPE_OF_CNV.append(ID__CNV__IDENTICAL)\n",
    "\n",
    "LATEX_TABLES = []\n",
    "for i in range(int(len(tmp1)/2)):\n",
    "    LATEX_TABLES.append(convert__tables(content[tmp1[2*i]:tmp1[2*i+1]]))\n",
    "\n",
    "\n",
    "# for i, L in enum(content):\n",
    "\n",
    "#     for idx_table in IDX__TABLES:\n",
    "#         LATEX_TABLES.append(convert__tables(content[idx_table[0]:idx_table[1]]))\n",
    "content = symbol_replacement(content, PARS)   \n",
    "content = bold_font(content)\n",
    "content = non_embedded_references_converter(content)\n",
    "\n",
    "LATEX = []\n",
    "i0 = IDX__TABLES[0]\n",
    "i_tables = 0\n",
    "for j, i in enum(IDX__TABLES[1:]):\n",
    "    if TYPE_OF_CNV[j] == ID__CNV__IDENTICAL:\n",
    "        LATEX += content[i0:i]\n",
    "    elif TYPE_OF_CNV[j] == ID__CNV__TABLE_STARTED:\n",
    "        LATEX += LATEX_TABLES[i_tables]\n",
    "        i_tables += 1\n",
    "    \n",
    "    i0 = i\n",
    "    \n",
    "LATEX = replace_hyperlinks(LATEX)\n",
    "\n",
    "PREAMBLE = ['\\documentclass{article}'] + package_loader() + ['\\n'*2] + ['\\setcounter{secnumdepth}{4}'] + ['\\\\begin{document}']\n",
    "\n",
    "\n",
    "LATEX = PREAMBLE + LATEX + ['\\end{document}']\n",
    "with open(PATHS['tex-file'], 'w', encoding='utf8') as f:\n",
    "    for l in LATEX:\n",
    "        if not l.endswith('\\n'): l+='\\n'\n",
    "        f.write(l)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugginng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [('Pasted image 20221127213454.png', '|500')]]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_references_recognizer(['This is ![[Pasted image 20221127213454.png|500]]'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars = '\\w' + SPECIAL_CHARACTERS + '\\[\\]'\n",
    "\n",
    "pattern = r\"\\[([^\\]]+)\\]\"\n",
    "regexMdLinks = '/\\[([^\\[]+)\\](\\(.*\\))'\n",
    "s = '[some example]' \n",
    "s = '[Could not install packages due to an OSError: WinError 5 Access is denied](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "match = re.findall(regexMdLinks, s)\n",
    "match\n",
    "\n",
    "\n",
    "# pattern = r\"\\[([^\\]]+)\\]\\(([^\\)]+)\\)\"\n",
    "\n",
    "# pattern = r\"\\[([^\\]]+)\\]\\(([^\\)]+)\\)\"\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "\n",
    "\n",
    "# s = 'example with [linking a website](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "\n",
    "# match = re.findall(pattern, s)\n",
    "# match\n",
    "\n",
    "# import re\n",
    "\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "\n",
    "# text = r\"[some sentence with [brackets] or (parentheses) inside it](some website)\"\n",
    "\n",
    "# match = re.findall(pattern, text)\n",
    "# match\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Could not install packages due to an OSError: WinError 5 Access is denied', 'https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied')\n",
      "\\href{https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied}{Could not install packages due to an OSError: WinError 5 Access is denied}\n"
     ]
    }
   ],
   "source": [
    "# Anything that isn't a square closing bracket\n",
    "name_regex = \"[^]]+\"\n",
    "# http:// or https:// followed by anything but a closing paren\n",
    "url_regex = \"http[s]?://[^)]+\"\n",
    "text = '[Could not install packages due to an OSError: WinError 5 Access is denied](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "\n",
    "markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "\n",
    "\n",
    "for match in re.findall(markup_regex, text):\n",
    "    print(match)\n",
    "    markdown_link = '[' + match[0] + '](' + match[1] + ')'\n",
    "    latex_link = \"\\\\href{\" + match[1] + \"}{\" + match[0] + \"}\"\n",
    "    print(text.replace(markdown_link, latex_link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First line is gooooood',\n",
       " 'Second line has ',\n",
       " 'Third line has  comments ',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_markdown_comments(S):\n",
    "    result = []\n",
    "    in_comment = False\n",
    "    for line in S:\n",
    "        comment_start = line.find(\"%%\")\n",
    "        while comment_start != -1:\n",
    "            comment_end = line.find(\"%%\", comment_start + 2)\n",
    "            if comment_end == -1:\n",
    "                line = line[:comment_start]\n",
    "                in_comment = True\n",
    "                break\n",
    "            else:\n",
    "                line = line[:comment_start] + line[comment_end + 2:]\n",
    "                comment_start = line.find(\"%%\")\n",
    "        if in_comment:\n",
    "            comment_end = line.find(\"%%\")\n",
    "            if comment_end != -1:\n",
    "                line = line[comment_end + 2:]\n",
    "                in_comment = False\n",
    "            else:\n",
    "                line = \"\"\n",
    "        result.append(line)\n",
    "    return result\n",
    "\n",
    "\n",
    "S = [\n",
    "    'First line is gooooood',\n",
    "    'Second line has %%comment%%',\n",
    "    'Third line has %% two %% comments %% yall%%',\n",
    "    'Fourth line has %% starting comment',\n",
    "    'which %% ends in fifth %% but starts again %%'\n",
    "]\n",
    "\n",
    "# ['First line is gooooood', 'Second line has ', 'Third line has  comments ', 'Fourth line has %% starting comment', ' ends in fifth ']\n",
    "remove_markdown_comments(S)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal links/crossrefs\n",
    "\n",
    "Using this format:\n",
    "\n",
    "\\section{Hello World}\n",
    "\\label{sec:hello}\n",
    "\n",
    "\n",
    "\\hyperref[sec:hello]{Word of text}\n",
    "\n",
    "\n",
    "### Strategy\n",
    "1. Add the label with the same name as in the Obsidian note. Add it just using \"\\n \\label{sec:label}\" instead of creating a new line\n",
    "2. Map the sections and blocks so that we can correspond them easily\n",
    "\n",
    "\n",
    "\n",
    "## Limitations\n",
    "\n",
    "### Hyperlinks\n",
    "- The pattern does not take account for the cases wherein there's more brackets inside the brackets\n",
    "\n",
    "\n",
    "### Cannot understand Windows emojis\n",
    "\n",
    "--> Use [this list of symbols](https://milde.users.sourceforge.net/LUCR/Math/mathpackages/amssymb-symbols.pdf) instead and the `\\usepackage{amssymb}` command\n",
    "\n",
    "\n",
    "\n",
    "## Programming mistakes/weaknesses in the code\n",
    "1. Redundant replacement in: \"⚠WARNING--1\" (search for it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa67766ae418968f0c59ac0eb4df618cb98e2442e22a4762b28c70784bead217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
