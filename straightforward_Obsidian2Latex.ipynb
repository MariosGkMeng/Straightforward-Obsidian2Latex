{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Tasks\n",
    "\n",
    "- ‚ûï Need to add the LateX command \"\\newline\" after equations that start with single \"$\"\n",
    "    - Even better: add same command before the equation, but twice\n",
    "        - HOWEVER, this problem would not be triggered if the author writes the equations with double \"$\"s\n",
    "- ‚ûï remove markdown comments from embedded files\n",
    "- ‚ûï Embedded refs, when a certain section is referenced: Need to change the hierarchy of potential \"inner sections\"\n",
    "- ‚ûï non-embedded external links --> remove Markdown linking format and add selection in the settings for the user to choose if they want to convert that reference to pdf as well and create hyperlink in the original pdf to that pdf\n",
    "\n",
    "- ‚ûï section recognition from embedded notes does not work (test with \"Assignment--11.md\" and see \"# Embedded-Section-Error\" comment in \"embedded_notes.py\")\n",
    "- ‚ûï Make it possible for internal links to have LateX write the number of page, in case the reader wants to print it\n",
    "- ‚ö†‚ûï When we are in a hyperlink, the underscore makes LateX expect a subscript: [error link](https://tex.stackexchange.com/questions/292037/url-causes-missing-inserted-error). Example \"\\hyperlink{sNO Intuitive-Explanation}{ADD_NAME}\" must be turned to \"\\hyperlink{sNO Intuitive-Explanation}{ADD\\_NAME}\"\n",
    "\n",
    "\n",
    "## Math-related\n",
    "- ‚ö† When parentheses are part of the reference note name, the regex recognition fails\n",
    "\n",
    "\n",
    "## Error cases\n",
    "- Try these two lines: \n",
    "From [[Support Vector Machine (SVM)]]\n",
    "[[kernel]]\n",
    "\n",
    "for some reason, the code merges them into one line\n",
    "\n",
    "## Edge cases\n",
    "- ‚ûï Consider case wherein there's more than one sections with the same name\n",
    "\n",
    "\n",
    "For the markdown comment removal, use for testing:\n",
    "- [[p514--notes]]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "## Prerequisites\n",
    "1. Have Python 3 installed\n",
    "\n",
    "\n",
    "\n",
    "## Usage\n",
    "For each user-defined parameter, go to the [User Parameters](#user-parameters) section, wherein the 'PARS' dictionary is located.\n",
    "\n",
    "To set the paths for the .md file to be converted, change the `PARS['üìÇ']['markdown-file']` and `PARS['üìÇ']['tex-file']`.\n",
    "Then, just run all code blocks and VOILA!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from remove_markdown_comment import *\n",
    "from symbol_replacements import *\n",
    "from embedded_notes import *\n",
    "from bullet_list__converter import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dict(D):\n",
    "    for key, value in D.items():\n",
    "        if value == 'üü¢':\n",
    "            D[key] = True\n",
    "        elif value == 'üî¥':\n",
    "            D[key] = False\n",
    "        elif isinstance(value, dict):\n",
    "            D[key] = conv_dict(value)\n",
    "    return D\n",
    "\n",
    "\n",
    "# is_in_table_line = lambda x: x.startswith('|') and x.endswith('|')\n",
    "# enum             = lambda x: enumerate(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants (to not be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID__TABLES__alignment__center = 0\n",
    "ID__TABLES__alignment__right  = 1\n",
    "ID__TABLES__alignment__middle = 2\n",
    "\n",
    "\n",
    "ID__TABLES__PACKAGE__longtblr   = 0\n",
    "ID__TABLES__PACKAGE__tabularx   = 1\n",
    "ID__TABLES__PACKAGE__long_table = 2\n",
    "\n",
    "ID__CNV__TABLE_STARTED      = 0\n",
    "ID__CNV__TABLE_ENDED        = 1\n",
    "ID__CNV__IDENTICAL          = 2\n",
    "\n",
    "ID__STYLE__BOLD             = 0\n",
    "ID__STYLE__HIGHLIGHTER      = 1\n",
    "\n",
    "# ‚ö† does not work for longtblr!\n",
    "CMD__TABLE__TABULARX__CENTERING = '\\\\newcolumntype{Y}{>{\\\\centering\\\\arraybackslash}X}'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files  = 'C:\\\\Users\\\\mariosg\\\\OneDrive - NTNU\\\\FILES\\\\workTips\\\\'\n",
    "path0       = path_files + 'AUTOMATIONS\\\\'\n",
    "path_file   = path_files + 'P-Tasks\\\\‚úî\\\\Assignment--11'\n",
    "\n",
    "\n",
    "PARS = conv_dict({\n",
    "    '‚öô': # SETTINGS\n",
    "        {'TABLES':{\n",
    "                            'package': ID__TABLES__PACKAGE__long_table,\n",
    "                'hlines-to-all-rows': 'üî¥',\n",
    "                 'any-hlines-at-all': 'üî¥',\n",
    "                         'alignment': [\n",
    "                                        ID__TABLES__alignment__center,\n",
    "                                        ID__TABLES__alignment__middle],\n",
    "                        'rel-width': 1.2\n",
    "                },\n",
    "                      'margin': '0.9in',\n",
    "                  'EXCEPTIONS': \n",
    "                                {\n",
    "                                    'raise_exception__when__embedded_reference_not_found': 'üî¥'\n",
    "                                    },\n",
    "                     'EMBEDDED REFERENCES':  \n",
    "                                        {'convert non embedded references': 'üî¥'}  # if True, then references such as \"[[another note]]\" will be changed to \"another note\". If FAlse, they will remain as is\n",
    "                                          },                \n",
    "    'üìÅ':\n",
    "           {\n",
    "                'markdown-file': path_file+'.md',  # Markdown (.md) file for conversio=n\n",
    "                     'tex-file': path_file+'.tex',  # LateX (.tex) file (converted from the .md file)\n",
    "                        'vault': path_files\n",
    "            },\n",
    "    'par':\n",
    "        {\n",
    "            'tabular-package':\n",
    "                            {\n",
    "                                       'names': ['longtblr', 'tabularx'],\n",
    "                                'before-lines': ['{colspec}']\n",
    "                            },\n",
    "            'packages-to-load':[                    # Which packages to load on the LateX preable\n",
    "                                'hyperref',\n",
    "                                'graphicx',\n",
    "                                'amssymb',           # need more symbols\n",
    "                                'titlesec',          # so that we can add more subsections (using 'paragraph')\n",
    "                                'xcolor, soul',      # for the highlighter\n",
    "                                'amsmath',\n",
    "                                'amsfonts',\n",
    "                                'cancel'\n",
    "                                ],\n",
    "          'symbols-to-replace': [       # Obsidian symbol, latex symbol,            type of replacement (1 or 2)\n",
    "                                        ['‚úî',              '\\\\checkmark',            1],\n",
    "                                        ['üü¢',              '$\\\\\\\\blacklozenge$',    2],\n",
    "                                        ['üî¥',              '\\\\\\maltese',            2],\n",
    "                                        ['‚ûï',              '\\\\boxplus',             2],\n",
    "                                        ['üîó',              'LINK',                  1],\n",
    "                                        ['\\implies',        '\\Rightarrow',            1],\n",
    "                                        ['‚ùì',              '?',                      1],\n",
    "                                        ['‚ùå',              'NO',                     1],\n",
    "                                        ['ü§î',               '',                      1],\n",
    "                                        ['‚ö†',               '!!',                      1],\n",
    "                                        ['\\\\text',          '\\\\textnormal',           1]\n",
    "                                        ]\n",
    "        }\n",
    "        \n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_loader():\n",
    "\n",
    "    packages_to_load    = []\n",
    "    packages_to_load +=PARS['par']['packages-to-load']\n",
    "    \n",
    "    tables_package      = PARS['‚öô']['TABLES']['package']\n",
    "    page_margin         = PARS['‚öô']['margin']\n",
    "\n",
    "    if tables_package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        packages_to_load.append('tabularray')\n",
    "        packages_to_load.append('longtable')\n",
    "\n",
    "    elif tables_package == ID__TABLES__PACKAGE__tabularx:\n",
    "        \n",
    "        packages_to_load.append('tabularx')\n",
    "\n",
    "    elif tables_package == ID__TABLES__PACKAGE__long_table:\n",
    "\n",
    "        packages_to_load.append('longtable')\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Nothing coded for this case\")\n",
    "\n",
    "        \n",
    "\n",
    "    out = ['\\\\usepackage{'+x+'}' for x in packages_to_load]\n",
    "    \n",
    "    \n",
    "    if len(page_margin) > 0:\n",
    "        out.append('\\\\usepackage[margin='+ page_margin + ']{geometry}')\n",
    " \n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def replace_hyperlinks(S):\n",
    "    \n",
    "\n",
    "    # Anything that isn't a square closing bracket\n",
    "    name_regex = \"[^]]+\"\n",
    "    # http:// or https:// followed by anything but a closing paren\n",
    "    url_regex = \"http[s]?://[^)]+\"\n",
    "\n",
    "    markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "\n",
    "    S_1 = []\n",
    "    for s in S:\n",
    "        s1 = s \n",
    "\n",
    "        for match in re.findall(markup_regex, s1):\n",
    "            markdown_link = '[' + match[0] + '](' + match[1] + ')'\n",
    "            latex_link = \"\\\\href{\" + match[1] + \"}{\" + match[0] + \"}\"\n",
    "            s1 = s1.replace(markdown_link, latex_link)\n",
    "\n",
    "        S_1.append(s1)\n",
    "    \n",
    "    return S_1\n",
    "\n",
    "def identify__tables(S):\n",
    "\n",
    "    table_indexes = []\n",
    "    table_has_started = False\n",
    "    for i, l in enum(S):\n",
    "        lstr = l.lstrip().rstrip()\n",
    "        is_table_line = is_in_table_line(lstr)        \n",
    "        if is_table_line and (not table_has_started):\n",
    "            table_has_started = True\n",
    "            idx__table_start = i\n",
    "        # ‚ö† NEVER add \"or (i == len(S)-1)\" to the condition below    \n",
    "        elif (not is_table_line and table_has_started):\n",
    "            table_has_started = False\n",
    "            idx__table_end = i\n",
    "            table_indexes.append(idx__table_start)\n",
    "            table_indexes.append(idx__table_end)\n",
    "\n",
    "    return table_indexes\n",
    "\n",
    "\n",
    "\n",
    "def simple_stylistic_replacements(S, type=None):\n",
    "\n",
    "\n",
    "    '''\n",
    "    For simple stylistic replacements. Includes conversions of:\n",
    "    - Bold font\n",
    "    - Highlighted font\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if type == ID__STYLE__BOLD:\n",
    "        style_char = '\\*\\*'\n",
    "        replacement_func = lambda repl, string:  repl.append(['**'+string+'**', '\\\\textbf{' + string + '}'])\n",
    "        l = 2\n",
    "    \n",
    "    elif type == ID__STYLE__HIGHLIGHTER:\n",
    "        style_char = '\\=\\='\n",
    "        replacement_func = lambda repl, string:  repl.append(['=='+string+'==', '\\hl{' + string + '}'])\n",
    "        l = 2\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "\n",
    "    S1 = []\n",
    "    for s in S:\n",
    "        occurences = [x.start() for x in re.finditer(style_char, s)]\n",
    "        L = len(occurences)\n",
    "\n",
    "        if L % l == 0:\n",
    "            replacements = []\n",
    "            for i in range(int(L/l)):\n",
    "                o0 = occurences[l*i]\n",
    "                o1 = occurences[l*i+1]\n",
    "                replacement_func(replacements, s[o0+l:o1])\n",
    "                \n",
    "            for R in replacements:\n",
    "                s = s.replace(R[0], R[1])\n",
    "        else:\n",
    "            raise Exception(\"error for this case, for now\")\n",
    "        \n",
    "        S1.append(s)\n",
    "    \n",
    "    return S1\n",
    "\n",
    " \n",
    "def convert__tables(S):\n",
    "    '''\n",
    "    Converts tables depending on the user's preferences    \n",
    "    '''\n",
    "\n",
    "    TABLE_SETTINGS = PARS['‚öô']['TABLES']\n",
    "    package = TABLE_SETTINGS['package']\n",
    "    add_txt = ''\n",
    "    if (ID__TABLES__alignment__center in TABLE_SETTINGS['alignment']) \\\n",
    "        and package == ID__TABLES__PACKAGE__longtblr:\n",
    "        add_txt = '\\centering '\n",
    "\n",
    "\n",
    "    # After having found the table\n",
    "    ## We expect that the 1st line defines the columns\n",
    "\n",
    "    cols = S[0].split('|')\n",
    "    cols = [[x.lstrip().rstrip() for x in cols if len(x)>0 and x!='\\n']]\n",
    "\n",
    "    data = []\n",
    "    for s in S[2:]:\n",
    "        c = s.split('|')\n",
    "        c = [x.lstrip().rstrip() for x in c if len(x.lstrip().rstrip())>0 and x!='\\n']\n",
    "        data.append(c)\n",
    "\n",
    "    y = cols + data\n",
    "\n",
    "    # CONVERT\n",
    "    N_cols = len(cols[0])\n",
    "\n",
    "    latex_table = []\n",
    "    addText = ''\n",
    "    for i, c in enum(y):\n",
    "        c1 = [add_txt + x for x in c]\n",
    "        if i==0: \n",
    "            if TABLE_SETTINGS['any-hlines-at-all']:\n",
    "                addText = ' \\hline'\n",
    "        else:\n",
    "            if TABLE_SETTINGS['hlines-to-all-rows']:\n",
    "                addText = ' \\hline'\n",
    "        latex_table.append('    ' + \" & \".join(c1) + ' \\\\\\\\' + addText)\n",
    "\n",
    "    lbefore = []\n",
    "\n",
    "\n",
    "    if package == ID__TABLES__PACKAGE__tabularx:\n",
    "\n",
    "\n",
    "        PCKG_NAME = '{tabularx}'\n",
    "\n",
    "        if ID__TABLES__alignment__center in TABLE_SETTINGS['alignment']:\n",
    "            lbefore.append(CMD__TABLE__TABULARX__CENTERING)\n",
    "            colPrefix = 'Y'\n",
    "        else:\n",
    "            colPrefix = 'X'\n",
    "\n",
    "        if (ID__TABLES__alignment__middle in TABLE_SETTINGS['alignment']):\n",
    "            lbefore.append('\\\\renewcommand\\\\tabularxcolumn[1]{m{#1}}')\n",
    "\n",
    "        latex_before_table = lbefore + [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin'+PCKG_NAME+'{\\\\textwidth}{' + '|' + N_cols*(colPrefix+'|') + '}',\n",
    "            '   \\hline'\n",
    "        ]\n",
    "\n",
    "        latex_after_table = [\n",
    "            '   \\hline',\n",
    "            '\\end'+PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        LATEX = latex_before_table + latex_table + latex_after_table\n",
    "\n",
    "    elif package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        PCKG_NAME = '{longtblr}'\n",
    "\n",
    "        latex_before_table = [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin' + PCKG_NAME + '[',\n",
    "            'caption = {},',\n",
    "            'entry = {},',\n",
    "            'label = {},',\n",
    "            'note{a} = {},',\n",
    "            'note{$\\dag$} = {}]',\n",
    "            '   {colspec = {'+ N_cols*'X' +'}, width = ' + str(TABLE_SETTINGS['rel-width']) + '\\linewidth, hlines, rowhead = 2, rowfoot = 1}'\n",
    "            ]  \n",
    "\n",
    "        latex_after_table = [\n",
    "            '\\end' + PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        add_hline_at_end = False # to be moved to user settings\n",
    "        if add_hline_at_end:\n",
    "            latex_after_table = '   \\hline' + latex_after_table\n",
    "\n",
    "\n",
    "        LATEX = latex_before_table + latex_table + latex_after_table\n",
    "\n",
    "\n",
    "    elif package == ID__TABLES__PACKAGE__long_table:\n",
    "        PCKG_NAME = '{longtable}'\n",
    "\n",
    "        latex_before_table=[\n",
    "        \t'\\\\begin{center}',\n",
    "\t\t    '   \\\\begin{longtable}{' + N_cols*'c' + '}',\n",
    "\t\t\t'   \\caption{} \\\\\\\\',\n",
    "\t\t\t'   \\hline',\n",
    "\t\t\t'   '+latex_table[0],\n",
    "\t\t\t'   \\hline',\n",
    "\t\t\t'   \\endfirsthead % Use \\endfirsthead for the line after the first header',\n",
    "\t\t\t'   \\hline',\n",
    "\t\t\t'   \\endfoot',\n",
    "            ]\n",
    "\n",
    "        latex_after_table = [\n",
    "            '   \\end' + PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        LATEX = latex_before_table + ['    '+x for x in latex_table[1:]] + latex_after_table\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "    return LATEX\n",
    "\n",
    "\n",
    "def images_converter(images):\n",
    "\n",
    "    '''\n",
    "    Converts Images given the path of the image file\n",
    "    '''\n",
    "\n",
    "    # NOTES:\n",
    "    # --- \", height=0.5\\\\textheight\" addition causes the aspect ratio to break\n",
    "\n",
    "    TO_PRINT = []\n",
    "\n",
    "    for IM in images:\n",
    "        path_img = '\"' + IM[1].replace('\\\\', '/') + '\"'\n",
    "        label_img = IM[1].split('\\\\')[-1]\n",
    "        caption_short = 'Caption short'\n",
    "        caption_long = 'Caption long'\n",
    "\n",
    "        TO_PRINT.append(' \\n'.join([\n",
    "        '\\\\begin{figure}',\n",
    "        '\t\\centering',\n",
    "        '\t\\includegraphics[width=0.7\\linewidth]'+\\\n",
    "            '{\"'+path_img+'\"}',\n",
    "        '\t\\caption['+caption_short+']{'+caption_long+'}',\n",
    "        '\t\\label{fig:'+label_img+'}',\n",
    "        '\\end{figure}']))\n",
    "\n",
    "    return TO_PRINT\n",
    "\n",
    "def add_new_line_equations(S0):\n",
    "\n",
    "    # This function assumes that the '\\n' symbol hasn't been added yet\n",
    "    S = S0\n",
    "    for i, s in enum(S):\n",
    "\n",
    "        if not s.endswith('$$') and s.endswith('$'):\n",
    "            if i<len(S):\n",
    "                S[i+1] = '\\n' + S[i+1]\n",
    "\n",
    "        if not s.startswith('$$') and s.startswith('$'):\n",
    "            if i>0: \n",
    "                if not S[i-1].endswith('\\n'):\n",
    "                    S[i-1] = S[i-1] + '\\n'*2\n",
    "                else:\n",
    "                    S[i-1] = S[i-1] + '\\n'\n",
    "\n",
    "        # if not s.endswith('$$') and s.endswith('$'):\n",
    "        #     if i<len(S):\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "PATHS = PARS['üìÅ']\n",
    "\n",
    "with open(PATHS['markdown-file'], 'r', encoding='utf8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "\n",
    "content = remove_markdown_comments(content)\n",
    "\n",
    "# UNFOLD EMBEDDED NOTES ============================================================================================================================================\n",
    "md__files_embedded_prev0 = []\n",
    "md__files_embedded_prev = md__files_embedded_prev0.copy()\n",
    "[content, md__files_embedded_new] = unfold_embedded_notes(content, md__files_embedded_prev, PARS)\n",
    "\n",
    "while md__files_embedded_prev0 != md__files_embedded_new:\n",
    "    md__files_embedded_prev0 = md__files_embedded_new.copy()\n",
    "    md__files_embedded_prev = md__files_embedded_prev0.copy()\n",
    "    [content, md__files_embedded_new] = unfold_embedded_notes(content, md__files_embedded_prev, PARS)\n",
    "\n",
    "# ======================================================================================================================================================================\n",
    "\n",
    "# Convert bullet and numbered lists.\n",
    "content = bullet_list_converter(content)\n",
    "\n",
    "\n",
    "# Replace headers and map sections \\==================================================\n",
    "Lc = len(content)-1\n",
    "sections = []\n",
    "for i in range(Lc+1):\n",
    "    # ‚ö† The sequence of replacements matters: \n",
    "    # ---- replace the lowest-level subsections first\n",
    "    content_00 = content[i]\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'#### (.*)', r'\\\\paragraph{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('#### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'### (.*)', r'\\\\subsubsection{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'## (.*)', r'\\\\subsection{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('## ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'# (.*)', r'\\\\section{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('# ', '').replace('\\n', '')])\n",
    "\n",
    "# \\==================================================\\==================================================\n",
    "\n",
    "# find reference blocks \\==================================================\n",
    "#---1. they have to be at the end of the sentence (i.e. before \"\\n\")\n",
    "blocks = []\n",
    "for i in range(Lc+1):\n",
    "    s = content[i].replace('\\n', '')\n",
    "    pattern = r\"\\^[\\w\\-]*$\"\n",
    "    link_label = re.findall(pattern, s)\n",
    "    if len(link_label) > 0:\n",
    "        blocks.append([i, link_label[0].replace('^', '')])    \n",
    "# \\==================================================\n",
    "\n",
    "# Find and apply internal links\n",
    "internal_links = internal_links__identifier(content)\n",
    "content = internal_links__enforcer(content, [sections, blocks], internal_links)\n",
    "#\n",
    "\n",
    "# Convert figures \\==================================================\n",
    "\n",
    "embeded_refs = embedded_references_recognizer(content)\n",
    "\n",
    "# ‚ûï add more image refs\n",
    "# replace \"content[line_number]\" accordingly and see the result\n",
    "\n",
    "for i, ln in enum(embeded_refs):\n",
    "\n",
    "    line_number = ln[0]\n",
    "    line_refs = ln[1]\n",
    "    for lnrf in line_refs:\n",
    "\n",
    "        # print(embedded_references_path_finder(lnrf[0]))\n",
    "        converted_image_text = images_converter([[line_number, embedded_references_path_finder(lnrf[0], PARS)]])\n",
    "        \n",
    "        for img_txt_cnv in converted_image_text:\n",
    "            tmp1 = '![[' + lnrf[0]\n",
    "            if ('.png' in lnrf[0] or '.jpg' in lnrf[0]) and (lnrf[1].replace('|','')).isnumeric():\n",
    "                content[line_number] = content[line_number].replace(tmp1 + lnrf[1] + ']]', img_txt_cnv)\n",
    "            else:\n",
    "                content[line_number] = content[line_number].replace(tmp1 + ']]', img_txt_cnv)\n",
    "\n",
    "\n",
    "# \\==================================================\n",
    "content = add_new_line_equations(content)\n",
    "\n",
    "IDX__TABLES = [0]\n",
    "TYPE_OF_CNV = [ID__CNV__IDENTICAL]\n",
    "tmp1 = identify__tables(content)\n",
    "tmp2 = [ID__CNV__TABLE_STARTED for _ in tmp1]\n",
    "tmp2[1::2] = [ID__CNV__IDENTICAL for _ in tmp1[1::2]]\n",
    "IDX__TABLES += tmp1\n",
    "TYPE_OF_CNV += tmp2\n",
    "\n",
    "Lc = len(content)-1\n",
    "if IDX__TABLES[-1] < Lc: \n",
    "    IDX__TABLES.append(Lc)\n",
    "    TYPE_OF_CNV.append(ID__CNV__IDENTICAL)\n",
    "\n",
    "LATEX_TABLES = []\n",
    "for i in range(int(len(tmp1)/2)):\n",
    "    LATEX_TABLES.append(convert__tables(content[tmp1[2*i]:tmp1[2*i+1]]))\n",
    "\n",
    "\n",
    "# for i, L in enum(content):\n",
    "\n",
    "#     for idx_table in IDX__TABLES:\n",
    "#         LATEX_TABLES.append(convert__tables(content[idx_table[0]:idx_table[1]]))\n",
    "content = symbol_replacement(content, PARS)   \n",
    "content = simple_stylistic_replacements(content, type=ID__STYLE__BOLD)\n",
    "content = simple_stylistic_replacements(content, type=ID__STYLE__HIGHLIGHTER)\n",
    "\n",
    "if PARS['‚öô']['EMBEDDED REFERENCES']['convert non embedded references']:\n",
    "    content = non_embedded_references_converter(content)\n",
    "\n",
    "LATEX = []\n",
    "i0 = IDX__TABLES[0]\n",
    "i_tables = 0\n",
    "for j, i in enum(IDX__TABLES[1:]):\n",
    "    if TYPE_OF_CNV[j] == ID__CNV__IDENTICAL:\n",
    "        LATEX += content[i0:i]\n",
    "    elif TYPE_OF_CNV[j] == ID__CNV__TABLE_STARTED:\n",
    "        LATEX += LATEX_TABLES[i_tables]\n",
    "        i_tables += 1\n",
    "    \n",
    "    i0 = i\n",
    "    \n",
    "LATEX = replace_hyperlinks(LATEX)\n",
    "\n",
    "PREAMBLE = ['\\documentclass{article}'] + package_loader() + ['\\n'] + ['\\sethlcolor{yellow}'] + ['\\n'] + ['\\n'*2] + ['\\setcounter{secnumdepth}{4}'] + ['\\\\begin{document}']\n",
    "\n",
    "\n",
    "LATEX = PREAMBLE + LATEX + ['\\end{document}']\n",
    "with open(PATHS['tex-file'], 'w', encoding='utf8') as f:\n",
    "    for l in LATEX:\n",
    "        if not l.endswith('\\n'): l+='\\n'\n",
    "        f.write(l)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugginng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [('Pasted image 20221127213454.png', '|500')]]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_references_recognizer(['This is ![[Pasted image 20221127213454.png|500]]'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars = '\\w' + SPECIAL_CHARACTERS + '\\[\\]'\n",
    "\n",
    "pattern = r\"\\[([^\\]]+)\\]\"\n",
    "regexMdLinks = '/\\[([^\\[]+)\\](\\(.*\\))'\n",
    "s = '[some example]' \n",
    "s = '[Could not install packages due to an OSError: WinError 5 Access is denied](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "match = re.findall(regexMdLinks, s)\n",
    "match\n",
    "\n",
    "\n",
    "# pattern = r\"\\[([^\\]]+)\\]\\(([^\\)]+)\\)\"\n",
    "\n",
    "# pattern = r\"\\[([^\\]]+)\\]\\(([^\\)]+)\\)\"\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "\n",
    "\n",
    "# s = 'example with [linking a website](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "\n",
    "# match = re.findall(pattern, s)\n",
    "# match\n",
    "\n",
    "# import re\n",
    "\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "\n",
    "# text = r\"[some sentence with [brackets] or (parentheses) inside it](some website)\"\n",
    "\n",
    "# match = re.findall(pattern, text)\n",
    "# match\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Could not install packages due to an OSError: WinError 5 Access is denied', 'https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied')\n",
      "\\href{https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied}{Could not install packages due to an OSError: WinError 5 Access is denied}\n"
     ]
    }
   ],
   "source": [
    "# Anything that isn't a square closing bracket\n",
    "name_regex = \"[^]]+\"\n",
    "# http:// or https:// followed by anything but a closing paren\n",
    "url_regex = \"http[s]?://[^)]+\"\n",
    "text = '[Could not install packages due to an OSError: WinError 5 Access is denied](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "\n",
    "markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "\n",
    "\n",
    "for match in re.findall(markup_regex, text):\n",
    "    print(match)\n",
    "    markdown_link = '[' + match[0] + '](' + match[1] + ')'\n",
    "    latex_link = \"\\\\href{\" + match[1] + \"}{\" + match[0] + \"}\"\n",
    "    print(text.replace(markdown_link, latex_link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First line is gooooood',\n",
       " 'Second line has ',\n",
       " 'Third line has  comments ',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_markdown_comments(S):\n",
    "    result = []\n",
    "    in_comment = False\n",
    "    for line in S:\n",
    "        comment_start = line.find(\"%%\")\n",
    "        while comment_start != -1:\n",
    "            comment_end = line.find(\"%%\", comment_start + 2)\n",
    "            if comment_end == -1:\n",
    "                line = line[:comment_start]\n",
    "                in_comment = True\n",
    "                break\n",
    "            else:\n",
    "                line = line[:comment_start] + line[comment_end + 2:]\n",
    "                comment_start = line.find(\"%%\")\n",
    "        if in_comment:\n",
    "            comment_end = line.find(\"%%\")\n",
    "            if comment_end != -1:\n",
    "                line = line[comment_end + 2:]\n",
    "                in_comment = False\n",
    "            else:\n",
    "                line = \"\"\n",
    "        result.append(line)\n",
    "    return result\n",
    "\n",
    "\n",
    "S = [\n",
    "    'First line is gooooood',\n",
    "    'Second line has %%comment%%',\n",
    "    'Third line has %% two %% comments %% yall%%',\n",
    "    'Fourth line has %% starting comment',\n",
    "    'which %% ends in fifth %% but starts again %%'\n",
    "]\n",
    "\n",
    "# ['First line is gooooood', 'Second line has ', 'Third line has  comments ', 'Fourth line has %% starting comment', ' ends in fifth ']\n",
    "remove_markdown_comments(S)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal links/crossrefs\n",
    "\n",
    "Using this format:\n",
    "\n",
    "\\section{Hello World}\n",
    "\\label{sec:hello}\n",
    "\n",
    "\n",
    "\\hyperref[sec:hello]{Word of text}\n",
    "\n",
    "\n",
    "### Strategy\n",
    "1. Add the label with the same name as in the Obsidian note. Add it just using \"\\n \\label{sec:label}\" instead of creating a new line\n",
    "2. Map the sections and blocks so that we can correspond them easily\n",
    "\n",
    "\n",
    "\n",
    "## Limitations\n",
    "\n",
    "### Hyperlinks\n",
    "- The pattern does not take account for the cases wherein there's more brackets inside the brackets\n",
    "\n",
    "\n",
    "### Cannot understand Windows emojis\n",
    "\n",
    "--> Use [this list of symbols](https://milde.users.sourceforge.net/LUCR/Math/mathpackages/amssymb-symbols.pdf) instead and the `\\usepackage{amssymb}` command\n",
    "\n",
    "\n",
    "\n",
    "## Programming mistakes/weaknesses in the code\n",
    "1. Redundant replacement in: \"‚ö†WARNING--1\" (search for it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa67766ae418968f0c59ac0eb4df618cb98e2442e22a4762b28c70784bead217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
