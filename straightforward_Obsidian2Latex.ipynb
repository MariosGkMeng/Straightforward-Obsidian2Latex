{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from os.path import exists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dict(D):\n",
    "    for key in D.keys():\n",
    "        if D[key] == '🟢':\n",
    "            D[key] = True\n",
    "        elif D[key] == '🔴':\n",
    "            D[key] = False\n",
    "    return D\n",
    "\n",
    "\n",
    "is_in_table_line = lambda x: x.startswith('|') and x.endswith('|')\n",
    "enum             = lambda x: enum(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants (to not be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID__TABLES__table_alignment__center = 0\n",
    "ID__TABLES__table_alignment__right  = 1\n",
    "ID__TABLES__table_alignment__middle = 2\n",
    "\n",
    "\n",
    "ID__TABLES__PACKAGE__longtblr = 0\n",
    "ID__TABLES__PACKAGE__tabularx = 1\n",
    "\n",
    "ID__CNV__TABLE_STARTED      = 0\n",
    "ID__CNV__TABLE_ENDED        = 1\n",
    "ID__CNV__IDENTICAL          = 2\n",
    "\n",
    "# ⚠ does not work for longtblr!\n",
    "CMD__TABLE__TABULARX__CENTERING = '\\\\newcolumntype{Y}{>{\\\\centering\\\\arraybackslash}X}'\n",
    "\n",
    "# For recognizing file names, section names, block names\n",
    "SPECIAL_CHARACTERS = ' %💬⚠💼🟢➕❓🔴✔🧑☺📁⚙🔒🟡🔲💊💡🤷‍♂️▶📧🔗🎾👨‍💻📞💭📖ℹ🤖🏢🧠🕒👇📚👉0-9'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files  = 'C:\\\\Users\\\\mariosg\\\\OneDrive - NTNU\\\\FILES\\\\'\n",
    "path0       = path_files + 'AUTOMATIONS\\\\'\n",
    "\n",
    "\n",
    "PARS = conv_dict(dict({\n",
    "    '⚙': # SETTINGS\n",
    "        conv_dict(dict({'TABLES':  \n",
    "                conv_dict(dict({\n",
    "                                  'package': ID__TABLES__PACKAGE__longtblr,\n",
    "                       'hlines-to-all-rows': '🔴',\n",
    "                        'any-hlines-at-all': '🔴',\n",
    "                                'alignment': [\n",
    "                                                ID__TABLES__table_alignment__center,\n",
    "                                                ID__TABLES__table_alignment__middle],\n",
    "                                'rel-width': 1.2\n",
    "                }))})),\n",
    "    '📁':\n",
    "         dict({\n",
    "                'markdown-file': path_files + 'workTips\\\\Literature\\\\Notes\\\\🔗\\\\👩‍💻\\\\Python\\\\' + 'Python Notes and Issues.md',  # Markdown (.md) file for conversion\n",
    "                     'tex-file': path0 + 'example.tex',  # LateX (.tex) file (converted from the .md file)\n",
    "                        'vault': path_files + 'workTips\\\\'\n",
    "            }),\n",
    "    'par':\n",
    "        dict({\n",
    "            'tabular-package':\n",
    "                            dict({\n",
    "                                       'names': ['longtblr', 'tabularx'],\n",
    "                                'before-lines': ['{colspec}']\n",
    "                            })\n",
    "        })\n",
    "}))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def package_loader():\n",
    "\n",
    "    packages_to_load = [\n",
    "        'hyperref',\n",
    "        'graphicx',\n",
    "        'amssymb',           # need more symbols\n",
    "        'titlesec'           # so that we can add more subsections (using 'paragraph')\n",
    "         ]\n",
    "\n",
    "    tables_package = PARS['⚙']['TABLES']['package']\n",
    "    if tables_package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        packages_to_load.append('tabularray')\n",
    "        packages_to_load.append('longtable')\n",
    "\n",
    "    elif tables_package == ID__TABLES__PACKAGE__tabularx:\n",
    "        packages_to_load.append('tabularx')\n",
    "\n",
    "    return ['\\\\usepackage{'+x+'}' for x in packages_to_load]\n",
    "\n",
    "\n",
    "\n",
    "def symbol_replacement(S):\n",
    "    \n",
    "    SYMBOLS_TO_REPLACE = [\n",
    "        ['✔', '\\\\checkmark', 1],\n",
    "        ['🟢', '$\\\\\\\\blacklozenge$', 2],\n",
    "        ['🔴', '\\\\\\maltese', 2],\n",
    "        ['➕', '\\\\boxplus', 2],\n",
    "        ['🔗', 'LINK', 1]\n",
    "        ]\n",
    "    \n",
    "    S_1 = []\n",
    "    for i, s in enum(S):\n",
    "        s1 = s\n",
    "        for symbol in SYMBOLS_TO_REPLACE:\n",
    "            if symbol[2] == 1:\n",
    "                s1 = s1.replace(symbol[0], symbol[1] + ' ')\n",
    "            elif symbol[2] == 2:\n",
    "                s1 = re.sub(symbol[0], symbol[1] + ' ', s1)\n",
    "        S_1.append(s1)\n",
    "\n",
    "    return S_1\n",
    "\n",
    "\n",
    "def replace_hyperlinks(S):\n",
    "    \n",
    "    S_1 = []\n",
    "    for s in S:\n",
    "        s1 = s \n",
    "        words = s1.split()\n",
    "        latex = []\n",
    "        i = 0\n",
    "        while i < len(words):\n",
    "            if \"[\" in words[i]:\n",
    "                link_text = words[i].split(\"[\")[1]\n",
    "                i += 1\n",
    "                while \"]\" not in words[i]:\n",
    "                    link_text += \" \" + words[i]\n",
    "                    i += 1\n",
    "                link_text += \" \" + words[i].split(\"]\")[0]\n",
    "                link_url = words[i].split(\"](\")[1][:-1]\n",
    "                latex_link = \"\\\\href{\" + link_url + \"}{\" + link_text + \"}\"\n",
    "                latex.append(latex_link)\n",
    "            else:\n",
    "                latex.append(words[i])\n",
    "            i += 1\n",
    "        S_1.append(\" \".join(latex))\n",
    "\n",
    "    \n",
    "    return S_1\n",
    "\n",
    "# text = \"[Google](https://www.google.com)\"\n",
    "# print(md_to_latex_link(text))\n",
    "\n",
    "\n",
    "def identify__tables(S):\n",
    "\n",
    "    table_indexes = []\n",
    "    table_has_started = False\n",
    "    for i, l in enum(S):\n",
    "        lstr = l.lstrip().rstrip()\n",
    "        is_table_line = is_in_table_line(lstr)        \n",
    "        if is_table_line and (not table_has_started):\n",
    "            table_has_started = True\n",
    "            idx__table_start = i\n",
    "        # ⚠ NEVER add \"or (i == len(S)-1)\" to the condition below    \n",
    "        elif (not is_table_line and table_has_started):\n",
    "            table_has_started = False\n",
    "            idx__table_end = i\n",
    "            table_indexes.append(idx__table_start)\n",
    "            table_indexes.append(idx__table_end)\n",
    "\n",
    "\n",
    "    return table_indexes\n",
    "            \n",
    "\n",
    "def convert__tables(S):\n",
    "    '''\n",
    "    Converts tables    \n",
    "    '''\n",
    "\n",
    "    TABLE_SETTINGS = PARS['⚙']['TABLES']\n",
    "    package = TABLE_SETTINGS['package']\n",
    "    add_txt = ''\n",
    "    if (ID__TABLES__table_alignment__center in TABLE_SETTINGS['alignment']) \\\n",
    "        and package == ID__TABLES__PACKAGE__longtblr:\n",
    "        add_txt = '\\centering '\n",
    "\n",
    "\n",
    "    # After having found the table\n",
    "    ## We expect that the 1st line defines the columns\n",
    "\n",
    "    cols = S[0].split('|')\n",
    "    cols = [[x.lstrip().rstrip() for x in cols if len(x)>0 and x!='\\n']]\n",
    "\n",
    "    C = []\n",
    "    for s in S[2:]:\n",
    "        c = s.split('|')\n",
    "        c = [x.lstrip().rstrip() for x in c if len(x)>0 and x!='\\n']\n",
    "        C.append(c)\n",
    "\n",
    "    y = cols + C\n",
    "\n",
    "    # CONVERT\n",
    "    N_cols = len(cols[0])\n",
    "\n",
    "    latex_table = []\n",
    "    addText = ''\n",
    "    for i, c in enum(y):\n",
    "        c1 = [add_txt + x for x in c]\n",
    "        if i==0: \n",
    "            if TABLE_SETTINGS['any-hlines-at-all']:\n",
    "                addText = ' \\hline'\n",
    "        else:\n",
    "            if TABLE_SETTINGS['hlines-to-all-rows']:\n",
    "                addText = ' \\hline'\n",
    "        latex_table.append('    ' + \" & \".join(c1) + ' \\\\\\\\' + addText)\n",
    "\n",
    "    lbefore = []\n",
    "\n",
    "\n",
    "    if package == ID__TABLES__PACKAGE__tabularx:\n",
    "\n",
    "\n",
    "        PCKG_NAME = '{tabularx}'\n",
    "\n",
    "        if ID__TABLES__table_alignment__center in TABLE_SETTINGS['alignment']:\n",
    "            lbefore.append(CMD__TABLE__TABULARX__CENTERING)\n",
    "            colPrefix = 'Y'\n",
    "        else:\n",
    "            colPrefix = 'X'\n",
    "\n",
    "        if (ID__TABLES__table_alignment__middle in TABLE_SETTINGS['alignment']):\n",
    "            lbefore.append('\\\\renewcommand\\\\tabularxcolumn[1]{m{#1}}')\n",
    "\n",
    "        latex_before_table = lbefore + [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin'+PCKG_NAME+'{\\\\textwidth}{' + '|' + N_cols*(colPrefix+'|') + '}',\n",
    "            '   \\hline'\n",
    "        ]\n",
    "\n",
    "        latex_after_table = [\n",
    "            '   \\hline',\n",
    "            '\\end'+PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "    elif package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        PCKG_NAME = '{longtblr}'\n",
    "\n",
    "        latex_before_table = [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin' + PCKG_NAME + '[',\n",
    "            'caption = {},',\n",
    "            'entry = {},',\n",
    "            'label = {},',\n",
    "            'note{a} = {},',\n",
    "            'note{$\\dag$} = {}]',\n",
    "            '   {colspec = {'+ N_cols*'X' +'}, width = ' + str(TABLE_SETTINGS['rel-width']) + '\\linewidth, hlines, rowhead = 2, rowfoot = 1}'\n",
    "            ]  \n",
    "\n",
    "        latex_after_table = [\n",
    "            '\\end' + PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        add_hline_at_end = False # to be moved to user settings\n",
    "        if add_hline_at_end:\n",
    "            latex_after_table = '   \\hline' + latex_after_table\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "\n",
    "\n",
    "    LATEX = latex_before_table + latex_table + latex_after_table\n",
    "\n",
    "\n",
    "    return LATEX\n",
    "\n",
    "\n",
    "def internal_links__identifier(S):\n",
    "\n",
    "    if not isinstance(S, list):\n",
    "        raise Exception('Input of the function must be a list of strings!')\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "    pattern_sections = '\\[\\[([\\w-]+)\\#([\\w' + SPECIAL_CHARACTERS + '\\-]+)(\\|[\\w' + SPECIAL_CHARACTERS + '\\-]+)?\\]\\]'\n",
    "    pattern_blocks = '\\[\\[([\\w-]+)\\#\\^([\\w' + SPECIAL_CHARACTERS + '\\-]+)(\\|[\\w' + SPECIAL_CHARACTERS + '\\-]+)?\\]\\]'\n",
    "    \n",
    "    MATCHES = []\n",
    "    for i, s in enum(S):\n",
    "        match_sections = re.findall(pattern_sections, s)\n",
    "        match_blocks = re.findall(pattern_blocks, s)\n",
    "        if len(match_sections) != 0 or len(match_blocks) != 0:\n",
    "            MATCHES.append([i, match_sections, match_blocks])\n",
    "    \n",
    "    return MATCHES\n",
    "\n",
    "\n",
    "def internal_links__enforcer(S, sections_blocks, internal_links):\n",
    "\n",
    "    type_of_link = ['sec:', '']\n",
    "    type_of_link_obsidian = ['#', '#^']\n",
    "    sections = sections_blocks[0]\n",
    "    blocks = sections_blocks[1]\n",
    "    section_names = [x[1] for x in sections]\n",
    "    block_names = [x[1] for x in blocks]\n",
    "    for I in internal_links:\n",
    "        for iS in range(2):\n",
    "            Ii_sections = I[iS+1]\n",
    "            if len(Ii_sections) != 0:\n",
    "                \n",
    "                for i in Ii_sections:\n",
    "                    section_i = Ii_sections[0][1]\n",
    "                    idx = [j for j in range(len(sections_blocks[iS])) if sections_blocks[iS][j][1] == section_i]\n",
    "                    if len(idx)>0: \n",
    "                        idx=idx[0]\n",
    "\n",
    "                        label = type_of_link[iS] + section_i.replace(' ', '-')\n",
    "                        label_of_source = ' \\label{' + label + '}'\n",
    "                        hyperref_text = Ii_sections[0][-1].replace('|', '')\n",
    "                        if len(hyperref_text) != 0:\n",
    "                            hyperref_text = '{' + hyperref_text + '}'\n",
    "                        else:\n",
    "                            hyperref_text = '{' + 'ADD_NAME' + '}'\n",
    "\n",
    "                        if not label_of_source in S[sections_blocks[iS][idx][0]]:\n",
    "                            if iS==0:\n",
    "                                S[sections_blocks[iS][idx][0]] = S[sections_blocks[iS][idx][0]].replace('\\n', '')\\\n",
    "                                    + ' \\label{' + type_of_link[iS] + section_i.replace(' ', '-') + '}'\n",
    "                            else:\n",
    "                                S[sections_blocks[iS][idx][0]] = S[sections_blocks[iS][idx][0]].replace('\\n', '').replace('^' + label, '')\\\n",
    "                                    + ' \\label{' + type_of_link[iS] + section_i.replace(' ', '-') + '}'\n",
    "\n",
    "\n",
    "                        hyperref = '\\hyperref[' + label + ']' + hyperref_text\n",
    "\n",
    "                        obsidian_hyperref = '[[' + Ii_sections[0][0] + type_of_link_obsidian[iS] + Ii_sections[0][1] + Ii_sections[0][2] + ']]'\n",
    "                        S[I[0]] = S[I[0]].replace(obsidian_hyperref, hyperref)\n",
    "    return S\n",
    "\n",
    "\n",
    "def embedded_references_recognizer(S):\n",
    "\n",
    "\n",
    "    all_chars = '\\w' + SPECIAL_CHARACTERS\n",
    "    if not isinstance(S, list):\n",
    "        raise Exception('Input of the function must be a list of strings!')\n",
    "        return np.nan\n",
    "\n",
    "    pattern_embedded = '!\\[\\[([\\.'+all_chars+']+)(\\|[\\w' + SPECIAL_CHARACTERS + '\\-]+)?\\]\\]'\n",
    "    MATCHES = []\n",
    "    for i, s in enum(S):\n",
    "        match_pattern_embedded = re.findall(pattern_embedded, s)\n",
    "        if len(match_pattern_embedded) != 0:\n",
    "            MATCHES.append([i, match_pattern_embedded])\n",
    "            # path-finder\n",
    "\n",
    "    \n",
    "    return MATCHES\n",
    "\n",
    "\n",
    "def images_converter(images):\n",
    "\n",
    "\n",
    "    # NOTES:\n",
    "    # --- \", height=0.5\\\\textheight\" addition causes the aspect ratio to break\n",
    "\n",
    "    TO_PRINT = []\n",
    "\n",
    "    for IM in images:\n",
    "        path_img = '\"' + IM[1].replace('\\\\', '/') + '\"'\n",
    "        label_img = IM[1].split('\\\\')[-1]\n",
    "        caption_short = 'Caption short'\n",
    "        caption_long = 'Caption long'\n",
    "\n",
    "        TO_PRINT.append(' \\n'.join([\n",
    "        '\\\\begin{figure}',\n",
    "        '\t\\centering',\n",
    "        '\t\\includegraphics[width=0.7\\linewidth]'+\\\n",
    "            '{\"'+path_img+'\"}',\n",
    "        '\t\\caption['+caption_short+']{'+caption_long+'}',\n",
    "        '\t\\label{fig:'+label_img+'}',\n",
    "        '\\end{figure}']))\n",
    "\n",
    "    \n",
    "    return TO_PRINT\n",
    "\n",
    "\n",
    "def embedded_references_path_finder(u):\n",
    "\n",
    "    files = []\n",
    "    # for folder, subfolders, files in os.walk(PARS['📁']['vault']):\n",
    "    #    for f in files:\n",
    "    #     if f.endswith('.md'): files_md.append(f)\n",
    "    os.chdir(PARS['📁']['vault'])\n",
    "    for root, dirs, files in os.walk(PARS['📁']['vault']):\n",
    "        if u in files: return os.path.join(root,u)\n",
    "    return ''\n",
    "\n",
    "PATHS = PARS['📁']\n",
    "\n",
    "with open(PATHS['markdown-file'], 'r', encoding='utf8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "\n",
    "# Replace headers and map sections \\==================================================\n",
    "Lc = len(content)-1\n",
    "sections = []\n",
    "for i in range(Lc+1):\n",
    "    # ⚠ The sequence of replacements matters: \n",
    "    # ---- replace the lowest-level subsections first\n",
    "    content_00 = content[i]\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'#### (.*)', r'\\\\paragraph{\\1}', content[i])\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('#### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'### (.*)', r'\\\\subsubsection{\\1}', content[i])\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'## (.*)', r'\\\\subsection{\\1}', content[i])\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('## ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'# (.*)', r'\\\\section{\\1}', content[i])\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('# ', '').replace('\\n', '')])\n",
    "\n",
    "# \\==================================================\\==================================================\n",
    "\n",
    "# find reference blocks \\==================================================\n",
    "#---1. they have to be at the end of the sentence (i.e. before \"\\n\")\n",
    "blocks = []\n",
    "for i in range(Lc+1):\n",
    "    s = content[i].replace('\\n', '')\n",
    "    pattern = r\"\\^\\w*$\"\n",
    "    link_label = re.findall(pattern, s)\n",
    "    if len(link_label) > 0:\n",
    "        blocks.append([i, link_label[0].replace('^', '')])    \n",
    "# \\==================================================\n",
    "\n",
    "\n",
    "internal_links = internal_links__identifier(content)\n",
    "content = internal_links__enforcer(content, [sections, blocks], internal_links)\n",
    "\n",
    "\n",
    "# Convert figures \\==================================================\n",
    "\n",
    "embeded_refs = embedded_references_recognizer(content)\n",
    "\n",
    "# ➕ add more image refs\n",
    "# replace \"content[line_number]\" accordingly and see the result\n",
    "\n",
    "for i, ln in enum(embeded_refs):\n",
    "\n",
    "    line_number = ln[0]\n",
    "    line_refs = ln[1]\n",
    "    for lnrf in line_refs:\n",
    "\n",
    "        # print(embedded_references_path_finder(lnrf[0]))\n",
    "        converted_image_text = images_converter([[line_number, embedded_references_path_finder(lnrf[0])]])\n",
    "        for img_txt_cnv in converted_image_text:\n",
    "            content[line_number] = content[line_number].replace('![[' + lnrf[0] + ']]', img_txt_cnv)\n",
    "\n",
    "\n",
    "# \\==================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IDX__TABLES = [0]\n",
    "TYPE_OF_CNV = [ID__CNV__IDENTICAL]\n",
    "tmp1 = identify__tables(content)\n",
    "tmp2 = [ID__CNV__TABLE_STARTED for _ in tmp1]\n",
    "tmp2[1::2] = [ID__CNV__IDENTICAL for _ in tmp1[1::2]]\n",
    "IDX__TABLES += tmp1\n",
    "TYPE_OF_CNV += tmp2\n",
    "\n",
    "Lc = len(content)-1\n",
    "if IDX__TABLES[-1] < Lc: \n",
    "    IDX__TABLES.append(Lc)\n",
    "    TYPE_OF_CNV.append(ID__CNV__IDENTICAL)\n",
    "\n",
    "LATEX_TABLES = []\n",
    "for i in range(int(len(tmp1)/2)):\n",
    "    LATEX_TABLES.append(convert__tables(content[tmp1[2*i]:tmp1[2*i+1]]))\n",
    "\n",
    "\n",
    "# for i, L in enum(content):\n",
    "\n",
    "#     for idx_table in IDX__TABLES:\n",
    "#         LATEX_TABLES.append(convert__tables(content[idx_table[0]:idx_table[1]]))\n",
    "\n",
    "\n",
    "LATEX = []\n",
    "i0 = IDX__TABLES[0]\n",
    "i_tables = 0\n",
    "for j, i in enum(IDX__TABLES[1:]):\n",
    "    if TYPE_OF_CNV[j] == ID__CNV__IDENTICAL:\n",
    "        LATEX += content[i0:i]\n",
    "    elif TYPE_OF_CNV[j] == ID__CNV__TABLE_STARTED:\n",
    "        LATEX += LATEX_TABLES[i_tables]\n",
    "        i_tables += 1\n",
    "    \n",
    "    i0 = i\n",
    "    \n",
    "LATEX = symbol_replacement(LATEX)   \n",
    "LATEX = replace_hyperlinks(LATEX)\n",
    "\n",
    "PREAMBLE = ['\\documentclass{article}'] + package_loader() + ['\\n'*2] + ['\\setcounter{secnumdepth}{4}'] + ['\\\\begin{document}']\n",
    "\n",
    "\n",
    "LATEX = PREAMBLE + LATEX + ['\\end{document}']\n",
    "with open(PATHS['tex-file'], 'w', encoding='utf8') as f:\n",
    "    for l in LATEX:\n",
    "        if not l.endswith('\\n'): l+='\\n'\n",
    "        f.write(l)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugginng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think you should listen to \\\\hyperref[barbie1]{barbie} \\x08lacklozenge🔴'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG/PLAY\n",
    "\n",
    "# print(internal_links__identifier(content))\n",
    "# print('')\n",
    "\n",
    "# MATCHES = embedded_references_recognizer(content)\n",
    "# print(MATCHES[0][1][0][0])\n",
    "# embedded_references_path_finder(MATCHES[0][1][0][0])\n",
    "SYMBOLS_TO_REPLACE = [\n",
    "        ['✔', '\\checkmark'],\n",
    "        ['🟢', '\\\\blacklozenge'],\n",
    "        ['🔴', '\\\\\\maltese'],\n",
    "        ['➕', '\\\\boxplus'],\n",
    "        ['🔗', 'LINK']\n",
    "        ]\n",
    "\n",
    "ss1 = 'I think you should listen to \\hyperref[barbie1]{barbie} 🟢🔴'\n",
    "ss1 = re.sub(SYMBOLS_TO_REPLACE[1][0], SYMBOLS_TO_REPLACE[1][1], ss1) # ss1.replace(SYMBOLS_TO_REPLACE[0][0], SYMBOLS_TO_REPLACE[0][1])\n",
    "\n",
    "ss1\n",
    "# print(embedded_references_recognizer(content))\n",
    "# print(images_converter([[36, 'C:\\\\Users\\mariosg\\OneDrive - NTNU\\FILES\\workTips\\Literature\\\\Notes\\Pasted image 20220724202234.png']])[0])\n",
    "\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_refs = embedded_references_recognizer(content)\n",
    "line=embeded_refs[0][0]\n",
    "line_refs = embeded_refs[0][1]\n",
    "\n",
    "\n",
    "# ➕ add more image refs\n",
    "# replace \"content[line_number]\" accordingly and see the result\n",
    "\n",
    "for i, ln in enum(embeded_refs):\n",
    "\n",
    "\n",
    "    line_number = ln[0]\n",
    "    line_refs = ln[1]\n",
    "    for lnrf in line_refs:\n",
    "\n",
    "        # print(embedded_references_path_finder(lnrf[0]))\n",
    "        converted_image_text = images_converter([[line_number, lnrf[0]]])\n",
    "        for img_txt_cnv in converted_image_text:\n",
    "\n",
    "            print(img_txt_cnv)\n",
    "            content[line_number] = content[line_number].replace('![[' + lnrf[0] + ']]', img_txt_cnv)\n",
    "\n",
    "content\n",
    "# print(images_converter([[36, 'C:\\\\Users\\mariosg\\OneDrive - NTNU\\FILES\\workTips\\Literature\\\\Notes\\Pasted image 20220724202234.png']])[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal links/crossrefs\n",
    "\n",
    "Using this format:\n",
    "\n",
    "\\section{Hello World}\n",
    "\\label{sec:hello}\n",
    "\n",
    "\n",
    "\\hyperref[sec:hello]{Word of text}\n",
    "\n",
    "\n",
    "### Strategy\n",
    "1. Add the label with the same name as in the Obsidian note. Add it just using \"\\n \\label{sec:label}\" instead of creating a new line\n",
    "2. Map the sections and blocks so that we can correspond them easily\n",
    "\n",
    "\n",
    "\n",
    "## Limitations\n",
    "### Cannot understand Windows emojis\n",
    "\n",
    "--> Use [this list of symbols](https://milde.users.sourceforge.net/LUCR/Math/mathpackages/amssymb-symbols.pdf) instead and the `\\usepackage{amssymb}` command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c130fd4958ba2b097540499dcdcebb7bc79209faf2c439eb6c31cfb96e966f4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
