{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Tasks\n",
    "\n",
    "- âš  Embedded notes: if an embedded note embeds its parent, then an infinite loop of unfoldings will happen!\n",
    "- âš  Problems when doing the path_file = path_files + 'Literature\\\\Notes\\\\Equations\\\\in Machine Learning\\\\eq--loss function'\n",
    "\n",
    "- âž• Correct \"**BUG_1**\" in \"embedded_notes.py\"\n",
    "- âž• Correct \"**BUG_2**\" in \"embedded_notes.py\"\n",
    "- âž• Need to add the LateX command \"\\newline\" after equations that start with single \"$\"\n",
    "    - Even better: add same command before the equation, but twice\n",
    "        - HOWEVER, this problem would not be triggered if the author writes the equations with double \"$\"s\n",
    "- âž• remove markdown comments from embedded files\n",
    "- âž• Embedded refs, when a certain section is referenced: Need to change the hierarchy of potential \"inner sections\"\n",
    "- âž• non-embedded external links --> remove Markdown linking format and add selection in the settings for the user to choose if they want to convert that reference to pdf as well and create hyperlink in the original pdf to that pdf\n",
    "\n",
    "- âž• section recognition from embedded notes does not work (test with \"Assignment--11.md\" and see \"# Embedded-Section-Error\" comment in \"embedded_notes.py\")\n",
    "- âž• Make it possible for internal links to have LateX write the number of page, in case the reader wants to print it\n",
    "- âš âž• When we are in a hyperlink, the underscore makes LateX expect a subscript: [error link](https://tex.stackexchange.com/questions/292037/url-causes-missing-inserted-error). Example \"\\hyperlink{sNO Intuitive-Explanation}{ADD_NAME}\" must be turned to \"\\hyperlink{sNO Intuitive-Explanation}{ADD\\_NAME}\"\n",
    "\n",
    "\n",
    "## Tables\n",
    "- The tabularx |X|X| format does not help adjust to the length. The |l|l| adjusts to length, but does not perform text collapse, which is bad for long texts. Can I make a routine that recognizes when to put what?\n",
    "\n",
    "## Math-related\n",
    "- âš  When parentheses are part of the reference note name, the regex recognition fails\n",
    "\n",
    "\n",
    "## Error cases\n",
    "- Try these two lines: \n",
    "From [[Support Vector Machine (SVM)]]\n",
    "[[kernel]]\n",
    "- âš âš  Many problems with this: path_file = path_files + 'Meetings\\\\a few notes for the next meeting'\n",
    "    1. \"![[eq--task_loss_derivative#1]]\" is not recognized as an embedded reference!\n",
    "\n",
    "for some reason, the code merges them into one line\n",
    "\n",
    "## Edge cases\n",
    "- âž• Consider case wherein there's more than one sections with the same name\n",
    "\n",
    "\n",
    "For the markdown comment removal, use for testing:\n",
    "- [[p514--notes]]\n",
    "\n",
    "\n",
    "## Time optimization issues\n",
    "- âš Seems that having many embedded notes makes the code slowlier.\n",
    "    - âœ”Perhaps for the equation blocks, I could add an exception and deal with them later, in simpler manner\n",
    "    - âœ”Perhaps searching for their path every time creates the problem?\n",
    "- Perhaps all those string manipulations in the equations section are slowing it down\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "## Prerequisites\n",
    "1. Have Python 3 installed\n",
    "\n",
    "\n",
    "\n",
    "## Usage\n",
    "For each user-defined parameter, go to the [User Parameters](#user-parameters) section, wherein the 'PARS' dictionary is located.\n",
    "\n",
    "To set the paths for the .md file to be converted, change the `PARS['ðŸ“‚']['markdown-file']` and `PARS['ðŸ“‚']['tex-file']`.\n",
    "Then, just run all code blocks and VOILA!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from remove_markdown_comment import *\n",
    "from symbol_replacements import *\n",
    "from embedded_notes import *\n",
    "from bullet_list__converter import *\n",
    "from convert_code_blocks import code_block_converter\n",
    "from list_of_separate_lines import *\n",
    "from equations import *\n",
    "\n",
    "# For time profiling\n",
    "from cProfile import Profile\n",
    "from pstats import SortKey, Stats\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dict(D):\n",
    "    for key, value in D.items():\n",
    "        if value == 'ðŸŸ¢':\n",
    "            D[key] = True\n",
    "        elif value == 'ðŸ”´':\n",
    "            D[key] = False\n",
    "        elif isinstance(value, dict):\n",
    "            D[key] = conv_dict(value)\n",
    "    return D\n",
    "\n",
    "def python_format_path(path, to_python = False):\n",
    "    \n",
    "    if not to_python:\n",
    "        return path.replace('\\\\\\\\', '\\\\')\n",
    "    else:\n",
    "        return path.replace('\\\\', '\\\\\\\\')\n",
    "\n",
    "\n",
    "# is_in_table_line = lambda x: x.startswith('|') and x.endswith('|')\n",
    "# enum             = lambda x: enumerate(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python-style path: path1: C:\\Users\\Username\\Folder\\file.txt\n",
      "Standard path: path1: C:\\\\Users\\\\Username\\\\Folder\\\\file.txt\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "original_path = 'path1: C:\\\\Users\\\\Username\\\\Folder\\\\file.txt'\n",
    "\n",
    "# Convert to Python-style path\n",
    "python_style_path = python_format_path(original_path)\n",
    "print(\"Python-style path:\", python_style_path)  # Output: C:\\Users\\Username\\Folder\\file.txt\n",
    "\n",
    "# Convert back to standard path format\n",
    "standard_path = python_format_path(python_style_path, to_python=True)\n",
    "print(\"Standard path:\", standard_path)  # Output: C:\\\\Users\\\\Username\\\\Folder\\\\file.txt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants (to not be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID__TABLES__alignment__center = 0\n",
    "ID__TABLES__alignment__right  = 1\n",
    "ID__TABLES__alignment__middle = 2\n",
    "\n",
    "\n",
    "ID__TABLES__PACKAGE__longtblr   = 0\n",
    "ID__TABLES__PACKAGE__tabularx   = 1\n",
    "ID__TABLES__PACKAGE__long_table = 2\n",
    "\n",
    "ID__CNV__TABLE_STARTED      = 0\n",
    "ID__CNV__TABLE_ENDED        = 1\n",
    "ID__CNV__IDENTICAL          = 2\n",
    "\n",
    "ID__STYLE__BOLD             = 0\n",
    "ID__STYLE__HIGHLIGHTER      = 1\n",
    "ID__STYLE__ITALIC           = 2\n",
    "\n",
    "\n",
    "# âš  does not work for longtblr!\n",
    "CMD__TABLE__TABULARX__CENTERING = '\\\\newcolumntype{Y}{>{\\\\centering\\\\arraybackslash}X}'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files          = 'C:\\\\Users\\\\mariosg\\\\OneDrive - NTNU\\\\FILES\\\\workTips\\\\'\n",
    "path0               = path_files + 'AUTOMATIONS\\\\'\n",
    "path_file_testing   = path_files + 'code testing\\\\test_2'\n",
    "path_equation_blocks = path_files + 'âœWriting\\\\equation blocks'\n",
    "path_list_note_paths = path_files + 'DO_NOT_DELETE__note_paths.txt'\n",
    "# path_file = path_file_testing\n",
    "# \n",
    "path_file = path_files + 'âœWriting\\\\First working document'  #'Literature\\\\Notes\\\\Equations\\\\in Machine Learning\\\\eq--loss function'\n",
    "# path_file = path_files + 'Literature\\\\Straightforward-Obsidian2Latex\\\\example__automatic_equation_creation'\n",
    "\n",
    "PARS = conv_dict({\n",
    "    'âš™': # SETTINGS\n",
    "        {'TABLES':{\n",
    "                            'package': ID__TABLES__PACKAGE__tabularx,\n",
    "                'hlines-to-all-rows': 'ðŸŸ¢',\n",
    "                 'any-hlines-at-all': 'ðŸ”´',\n",
    "                         'alignment': [\n",
    "                                        ID__TABLES__alignment__center,\n",
    "                                        ID__TABLES__alignment__middle],\n",
    "                        'rel-width': 1.2\n",
    "                },\n",
    "        'margin': '0.9in',\n",
    "        'EXCEPTIONS': \n",
    "                    {'raise_exception__when__embedded_reference_not_found': 'ðŸ”´'},\n",
    "        'EMBEDDED REFERENCES':  \n",
    "                        {'convert_non_embedded_references': 'ðŸŸ¢',  # if True, then references such as \"[[another note]]\" will be changed to \"another note\". If FAlse, they will remain as is\n",
    "                         'treat_equation_blocks_separately': 'ðŸŸ¢', # if True, then the equation blocks are treated separately, in order to increase speed\n",
    "                                          'treat_citations': 'ðŸŸ¢'}, \n",
    "        'figures': \n",
    "                        {'reduce spacing between figures': 'ðŸ”´'},\n",
    "                                                       \n",
    "        'paragraph':{\n",
    "                    'indent_length_of_first_line': 0,    # 0 if no indent is desired. Recommended 20 for usual intent\n",
    "                    'if_text_before_first_section___place_before_table_of_contents': 'ðŸŸ¢'\n",
    "        }},\n",
    "    'ðŸ“': # Paths\n",
    "           {\n",
    "                'markdown-file': path_file+'.md',  # Markdown (.md) file for conversion\n",
    "                     'tex-file': path_file+'.tex',  # LateX (.tex) file (converted from the .md file)\n",
    "                        'vault': path_files,\n",
    "              'equation_blocks': path_equation_blocks,\n",
    "             'list_paths_notes': path_list_note_paths, # saves time from searching of the note's path\n",
    "             'bibtex_file_name': 'BIBTEX'              # your bibtex file name \n",
    "            },\n",
    "    'par':\n",
    "        {\n",
    "            'tabular-package':\n",
    "                            {\n",
    "                                       'names': ['longtblr', 'tabularx'],\n",
    "                                'before-lines': ['{colspec}']\n",
    "                            },\n",
    "            'packages-to-load':[    # Which packages to load on the LateX preable\n",
    "                                'hyperref',\n",
    "                                'graphicx',\n",
    "                                'amssymb',           # need more symbols\n",
    "                                'titlesec',          # so that we can add more subsections (using 'paragraph')\n",
    "                                'xcolor, soul',      # for the highlighter\n",
    "                                'amsmath',\n",
    "                                'amsfonts',\n",
    "                                'cancel',\n",
    "                                'minted',\n",
    "                                'apacite',           # apa citation style\n",
    "                                'caption'            # to set smaller vertical spacing between two figures\n",
    "                                ],\n",
    "          'symbols-to-replace': [       # Obsidian symbol, latex symbol,            type of replacement (1 or 2)\n",
    "                                        ['âœ”',              '\\\\checkmark',            1],\n",
    "                                        ['ðŸŸ¢',              '$\\\\\\\\blacklozenge$',    2],\n",
    "                                        ['ðŸ”´',              '\\\\\\maltese',            2],\n",
    "                                        ['âž•',              '**TODO: **',         2],    # Alternatives: ['$\\\\\\\\boxplus$']\n",
    "                                        ['ðŸ”—',              'LINK',                  1],\n",
    "                                        ['\\implies',        '\\Rightarrow',            1],\n",
    "                                        ['â“',              '?',                      1],\n",
    "                                        ['âŒ',              'NO',                    1],\n",
    "                                        ['ðŸ¤”',               '',                     1],\n",
    "                                        ['âš ',               '!!',                    1],\n",
    "                                        ['\\\\text',          '\\\\textnormal',          1]\n",
    "                                        ]\n",
    "        },\n",
    "    'EQUATIONS':\n",
    "               {'convert_non_numbered_to_numbered': 'ðŸŸ¢'}\n",
    "        \n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_loader():\n",
    "\n",
    "    packages_to_load    = []\n",
    "    packages_to_load +=PARS['par']['packages-to-load']\n",
    "    \n",
    "    tables_package      = PARS['âš™']['TABLES']['package']\n",
    "    page_margin         = PARS['âš™']['margin']\n",
    "\n",
    "    if tables_package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        packages_to_load.append('tabularray')\n",
    "        packages_to_load.append('longtable')\n",
    "\n",
    "    elif tables_package == ID__TABLES__PACKAGE__tabularx:\n",
    "        \n",
    "        packages_to_load.append('tabularx')\n",
    "\n",
    "    elif tables_package == ID__TABLES__PACKAGE__long_table:\n",
    "\n",
    "        packages_to_load.append('longtable')\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Nothing coded for this case\")\n",
    "\n",
    "    out = ['\\\\usepackage{'+x+'}' for x in packages_to_load]\n",
    "\n",
    "    paragraph_indent = f\"\\\\setlength{{\\\\parindent}}{{{str(PARS['âš™']['paragraph']['indent_length_of_first_line'])+'pt'}}}\"\n",
    "    out.append(paragraph_indent)\n",
    "    \n",
    "    if len(page_margin) > 0:\n",
    "        out.append('\\\\usepackage[margin='+ page_margin + ']{geometry}')\n",
    " \n",
    "\n",
    "\n",
    "    hyperlinkSetup=\"\"\"\n",
    "    \\hypersetup{\n",
    "    colorlinks   = true,    % Colours links instead of ugly boxes\n",
    "    urlcolor     = blue,    % Colour for external hyperlinks\n",
    "    linkcolor    = blue,    % Colour of internal links\n",
    "    citecolor    = red      % Colour of citations\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    out.append(hyperlinkSetup)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def replace_hyperlinks(S):\n",
    "    \n",
    "\n",
    "    # Anything that isn't a square closing bracket\n",
    "    name_regex = \"[^]]+\"\n",
    "    # http:// or https:// followed by anything but a closing paren\n",
    "    url_regex = \"http[s]?://[^)]+\"\n",
    "\n",
    "    markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "\n",
    "    S_1 = []\n",
    "    for s in S:\n",
    "        s1 = s \n",
    "\n",
    "        for match in re.findall(markup_regex, s1):\n",
    "            markdown_link = '[' + match[0] + '](' + match[1] + ')'\n",
    "            latex_link = \"\\\\href{\" + match[1] + \"}{\" + match[0] + \"}\"\n",
    "            s1 = s1.replace(markdown_link, latex_link)\n",
    "\n",
    "        S_1.append(s1)\n",
    "    \n",
    "    return S_1\n",
    "\n",
    "def identify__tables(S):\n",
    "\n",
    "    table_indexes = []\n",
    "    table_has_started = False\n",
    "    for i, l in enum(S):\n",
    "        lstr = l.lstrip().rstrip()\n",
    "        is_table_line = is_in_table_line(lstr)        \n",
    "        if is_table_line and (not table_has_started):\n",
    "            table_has_started = True\n",
    "            idx__table_start = i\n",
    "        # âš  NEVER add \"or (i == len(S)-1)\" to the condition below    \n",
    "        elif (not is_table_line and table_has_started):\n",
    "            table_has_started = False\n",
    "            idx__table_end = i\n",
    "            table_indexes.append(idx__table_start)\n",
    "            table_indexes.append(idx__table_end)\n",
    "\n",
    "    return table_indexes\n",
    "\n",
    "\n",
    "\n",
    "def simple_stylistic_replacements(S, type=None):\n",
    "\n",
    "\n",
    "    '''\n",
    "    For simple stylistic replacements. Includes conversions of:\n",
    "    - Bold font\n",
    "    - Highlighted font\n",
    "    - Italic font\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if type == ID__STYLE__BOLD:\n",
    "        style_char = '\\*\\*'\n",
    "        replacement_func = lambda repl, string:  repl.append(['**'+string+'**', '\\\\textbf{' + string + '}'])\n",
    "        l = 2\n",
    "        is_pair = True\n",
    "    \n",
    "    elif type == ID__STYLE__HIGHLIGHTER:\n",
    "        style_char = '\\=\\='\n",
    "        replacement_func = lambda repl, string:  repl.append(['=='+string+'==', '\\hl{' + string + '}'])\n",
    "        l = 2\n",
    "        is_pair = True\n",
    "\n",
    "    elif type == ID__STYLE__ITALIC:\n",
    "        style_char = '\\*'\n",
    "        replacement_func = lambda repl, string:  repl.append(['*'+string+'*', '\\\\textit{' + string + '}'])\n",
    "        l = 1\n",
    "        is_pair = True\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "\n",
    "    if is_pair:\n",
    "        l_iter = 2\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "\n",
    "    S1 = []\n",
    "    for s in S:\n",
    "        occurences = [x.start() for x in re.finditer(style_char, s)]\n",
    "        L = len(occurences)\n",
    "\n",
    "        if L % l == 0:\n",
    "            replacements = []\n",
    "            for i in range(int(L/l_iter)):\n",
    "                o0 = occurences[l*i]\n",
    "                o1 = occurences[l*i+1]\n",
    "                replacement_func(replacements, s[o0+l:o1])\n",
    "                \n",
    "            for R in replacements:\n",
    "                s = s.replace(R[0], R[1])\n",
    "        else:\n",
    "            raise Exception(\"error for this case, for now\")\n",
    "        \n",
    "        S1.append(s)\n",
    "    \n",
    "    return S1\n",
    "\n",
    " \n",
    "def convert__tables(S):\n",
    "    '''\n",
    "    Converts tables depending on the user's preferences    \n",
    "    '''\n",
    "\n",
    "    TABLE_SETTINGS = PARS['âš™']['TABLES']\n",
    "    package = TABLE_SETTINGS['package']\n",
    "    add_txt = ''\n",
    "    if (ID__TABLES__alignment__center in TABLE_SETTINGS['alignment']) \\\n",
    "        and package == ID__TABLES__PACKAGE__longtblr:\n",
    "        add_txt = '\\centering '\n",
    "\n",
    "\n",
    "    # After having found the table\n",
    "    ## We expect that the 1st line defines the columns\n",
    "\n",
    "    cols = S[0].split('|')\n",
    "    cols = [[x.lstrip().rstrip() for x in cols if len(x)>0 and x!='\\n']]\n",
    "\n",
    "    data = []\n",
    "    for s in S[2:]:\n",
    "        c = s.split('|')\n",
    "        c = [x.lstrip().rstrip() for x in c if len(x.lstrip().rstrip())>0 and x!='\\n']\n",
    "        data.append(c)\n",
    "\n",
    "    y = cols + data\n",
    "\n",
    "    # CONVERT\n",
    "    N_cols = len(cols[0])\n",
    "\n",
    "    latex_table = []\n",
    "    addText = ''\n",
    "    for i, c in enum(y):\n",
    "        c1 = [add_txt + x for x in c]\n",
    "        if i==0: \n",
    "            if TABLE_SETTINGS['any-hlines-at-all']:\n",
    "                addText = ' \\hline'\n",
    "        else:\n",
    "            if TABLE_SETTINGS['hlines-to-all-rows']:\n",
    "                addText = ' \\hline'\n",
    "        latex_table.append('    ' + \" & \".join(c1) + ' \\\\\\\\' + addText)\n",
    "\n",
    "    lbefore = []\n",
    "\n",
    "\n",
    "    if package == ID__TABLES__PACKAGE__tabularx:\n",
    "\n",
    "\n",
    "        PCKG_NAME = '{tabularx}'\n",
    "\n",
    "        if ID__TABLES__alignment__center in TABLE_SETTINGS['alignment']:\n",
    "            lbefore.append(CMD__TABLE__TABULARX__CENTERING)\n",
    "            colPrefix = 'Y'\n",
    "        else:\n",
    "            colPrefix = 'X'\n",
    "\n",
    "        if (ID__TABLES__alignment__middle in TABLE_SETTINGS['alignment']):\n",
    "            lbefore.append('\\\\renewcommand\\\\tabularxcolumn[1]{m{#1}}')\n",
    "\n",
    "        latex_before_table = lbefore + [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin'+PCKG_NAME+'{\\\\textwidth}{' + '|' + N_cols*(colPrefix+'|') + '}',\n",
    "            '   \\hline'\n",
    "        ]\n",
    "\n",
    "        latex_after_table = [\n",
    "            '   \\hline',\n",
    "            '\\end'+PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        LATEX = latex_before_table + latex_table + latex_after_table\n",
    "\n",
    "    elif package == ID__TABLES__PACKAGE__longtblr:\n",
    "\n",
    "        PCKG_NAME = '{longtblr}'\n",
    "\n",
    "        latex_before_table = [\n",
    "            '\\\\begin{center}',\n",
    "            '\\\\begin' + PCKG_NAME + '[',\n",
    "            'caption = {},',\n",
    "            'entry = {},',\n",
    "            'label = {},',\n",
    "            'note{a} = {},',\n",
    "            'note{$\\dag$} = {}]',\n",
    "            '   {colspec = {'+ N_cols*'X' +'}, width = ' + str(TABLE_SETTINGS['rel-width']) + '\\linewidth, hlines, rowhead = 2, rowfoot = 1}'\n",
    "            ]  \n",
    "\n",
    "        latex_after_table = [\n",
    "            '\\end' + PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        add_hline_at_end = False # to be moved to user settings\n",
    "        if add_hline_at_end:\n",
    "            latex_after_table = '   \\hline' + latex_after_table\n",
    "\n",
    "\n",
    "        LATEX = latex_before_table + latex_table + latex_after_table\n",
    "\n",
    "\n",
    "    elif package == ID__TABLES__PACKAGE__long_table:\n",
    "        PCKG_NAME = '{longtable}'\n",
    "\n",
    "        latex_before_table=[\n",
    "        \t'\\\\begin{center}',\n",
    "\t\t    '   \\\\begin{longtable}{' + N_cols*'c' + '}',\n",
    "\t\t\t'   \\caption{} \\\\\\\\',\n",
    "\t\t\t'   \\hline',\n",
    "\t\t\t'   '+latex_table[0],\n",
    "\t\t\t'   \\hline',\n",
    "\t\t\t'   \\endfirsthead % Use \\endfirsthead for the line after the first header',\n",
    "\t\t\t'   \\hline',\n",
    "\t\t\t'   \\endfoot',\n",
    "            ]\n",
    "\n",
    "        latex_after_table = [\n",
    "            '   \\end' + PCKG_NAME,\n",
    "            '\\end{center}'\n",
    "        ]\n",
    "\n",
    "        LATEX = latex_before_table + ['    '+x for x in latex_table[1:]] + latex_after_table\n",
    "    else:\n",
    "        raise Exception('NOTHING CODED HERE!')\n",
    "    return LATEX\n",
    "\n",
    "\n",
    "def images_converter(images, PARAMETERS):\n",
    "\n",
    "    '''\n",
    "    Converts Images given the path of the image file\n",
    "    '''\n",
    "\n",
    "    # NOTES:\n",
    "    # --- \", height=0.5\\\\textheight\" addition causes the aspect ratio to break\n",
    "\n",
    "    TO_PRINT = []\n",
    "    for IM in images:\n",
    "        path_img = '\"' + IM[1].replace('\\\\', '/') + '\"'\n",
    "        label_img = IM[1].split('\\\\')[-1]\n",
    "        caption_short = 'Caption short'\n",
    "        caption_long = 'Caption long'\n",
    "        figure_width = 0.7\n",
    "        TO_PRINT.append(' \\n'.join([\n",
    "        '\\\\begin{figure}',\n",
    "        '\t\\centering',\n",
    "        '\t\\includegraphics[width=' + str(figure_width) + '\\linewidth]'+\\\n",
    "            '{\"'+path_img+'\"}',\n",
    "        '\t\\caption['+caption_short+']{'+caption_long+'}',\n",
    "        '   \\captionsetup{skip=-10pt} % Adjust the skip value as needed'*PARAMETERS['reduce spacing between figures'],\n",
    "        '\t\\label{fig:'+label_img+'}',\n",
    "        '\\end{figure}']))\n",
    "\n",
    "    return TO_PRINT\n",
    "\n",
    "\n",
    "PATHS = PARS['ðŸ“']\n",
    "\n",
    "# open obsidian note\n",
    "with open(PATHS['markdown-file'], 'r', encoding='utf8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "\n",
    "content = remove_markdown_comments(content)\n",
    "\n",
    "# UNFOLD EMBEDDED NOTES ============================================================================================================================================\n",
    "md__files_embedded_prev0 = []\n",
    "md__files_embedded_prev = md__files_embedded_prev0.copy()\n",
    "\n",
    "lambda__unfold_embedded_notes = lambda x, y: unfold_embedded_notes(x, y, PARS, mode='normal')\n",
    "\n",
    "[content, md__files_embedded_new] = lambda__unfold_embedded_notes(content, md__files_embedded_prev)\n",
    "\n",
    "while md__files_embedded_prev0 != md__files_embedded_new:\n",
    "    md__files_embedded_prev0 = md__files_embedded_new.copy()\n",
    "    md__files_embedded_prev = md__files_embedded_prev0.copy()\n",
    "\n",
    "\n",
    "    # cProfile.run(\"lambda__unfold_embedded_notes(content, md__files_embedded_prev)\", \"my_func_stats\")\n",
    "\n",
    "    # p = pstats.Stats(\"my_func_stats\")\n",
    "\n",
    "\n",
    "    # with Profile() as profile:\n",
    "    #     print(f\"{lambda__unfold_embedded_notes(content, md__files_embedded_prev) = }\")\n",
    "    #     (\n",
    "    #         Stats(profile)\n",
    "    #         .strip_dirs()\n",
    "    #         .sort_stats(SortKey.CALLS)\n",
    "    #         .print_stats()\n",
    "    #     )\n",
    "\n",
    "\n",
    "    [content, md__files_embedded_new] = lambda__unfold_embedded_notes(content, md__files_embedded_prev)\n",
    "\n",
    "# ======================================================================================================================================================================\n",
    "\n",
    "# Convert bullet and numbered lists\n",
    "content = bullet_list_converter(content)\n",
    "\n",
    "\n",
    "# Replace headers and map sections \\==================================================\n",
    "Lc = len(content)-1\n",
    "sections = []\n",
    "for i in range(Lc+1):\n",
    "    # âš  The sequence of replacements matters: \n",
    "    # ---- replace the lowest-level subsections first\n",
    "    content_00 = content[i]\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'#### (.*)', r'\\\\paragraph{\\1} \\\\hspace{0pt} \\\\\\\\', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('#### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'### (.*)', r'\\\\subsubsection{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('### ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'## (.*)', r'\\\\subsection{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('## ', '').replace('\\n', '')])\n",
    "\n",
    "    content_0 = content[i]\n",
    "    content[i] = re.sub(r'# (.*)', r'\\\\section{\\1}', content[i].replace('%%', ''))\n",
    "    if content[i] != content_0:\n",
    "        sections.append([i, content_0.replace('# ', '').replace('\\n', '')])\n",
    "\n",
    "# \\==================================================\\==================================================\n",
    "\n",
    "\n",
    "# find reference blocks \\==================================================\n",
    "#---1. they have to be at the end of the sentence (i.e. before \"\\n\")\n",
    "Lc = len(content)-1\n",
    "blocks = []\n",
    "for i in range(Lc+1):\n",
    "    s = content[i].replace('\\n', '')\n",
    "    pattern = r\"\\^[\\w\\-]*$\"\n",
    "    link_label = re.findall(pattern, s)\n",
    "    if len(link_label) > 0:\n",
    "        blocks.append([i, link_label[0].replace('^', '')])    \n",
    "# \\==================================================\n",
    "\n",
    "# Find and apply internal links\n",
    "internal_links = internal_links__identifier(content)\n",
    "content = internal_links__enforcer(content, [sections, blocks], internal_links)\n",
    "#\n",
    "\n",
    "# Convert figures \\==================================================\n",
    "\n",
    "embeded_refs = embedded_references_recognizer(content, PARS['âš™']['EMBEDDED REFERENCES'], 'normal')\n",
    "\n",
    "# âž• add more image refs\n",
    "# replace \"content[line_number]\" accordingly and see the result\n",
    "\n",
    "for i, ln in enum(embeded_refs):\n",
    "\n",
    "    line_number = ln[0]\n",
    "    line_refs = ln[1]\n",
    "    for lnrf in line_refs:\n",
    "\n",
    "        converted_image_text = images_converter([[line_number, get_embedded_reference_path(lnrf[0], PARS)]], PARS['âš™']['figures'])\n",
    "        \n",
    "        for img_txt_cnv in converted_image_text:\n",
    "            tmp1 = '![[' + lnrf[0]\n",
    "            tmp2 = lnrf[2]\n",
    "\n",
    "            reference_is_image_with_manual_resize = ('.png' in lnrf[0] or '.jpg' in lnrf[0]) and (tmp2.replace('|','')).isnumeric()\n",
    "            content[line_number] = content[line_number].replace(tmp1 + tmp2*reference_is_image_with_manual_resize + ']]', img_txt_cnv)\n",
    "\n",
    "# \\==================================================\n",
    "# content = add_new_line_equations(content)\n",
    "\n",
    "\n",
    "\n",
    "if PARS['âš™']['EMBEDDED REFERENCES']['treat_equation_blocks_separately']:\n",
    "    # this means that all equation blocks were ignored, and we need to unfold them now\n",
    "    [content, md__files_embedded_new] = unfold_embedded_notes(content, [], PARS, mode='equation_blocks_only')\n",
    "\n",
    "    # check for references in those equations, and convert to LateX system\n",
    "    content = EQUATIONS__convert_equation_referencing(content)\n",
    "\n",
    "\n",
    "\n",
    "content = EQUATIONS__check_and_correct_aligned_equations(content)\n",
    "# problematic: C1 = content[109:114]\n",
    "\n",
    "if PARS['EQUATIONS']['convert_non_numbered_to_numbered']:\n",
    "    content = EQUATIONS__convert_non_numbered_to_numbered(content)\n",
    "    # Problematic: C1 = content[2:3]\n",
    "\n",
    "IDX__TABLES = [0]\n",
    "TYPE_OF_CNV = [ID__CNV__IDENTICAL]\n",
    "tmp1 = identify__tables(content)\n",
    "tmp2 = [ID__CNV__TABLE_STARTED for _ in tmp1]\n",
    "tmp2[1::2] = [ID__CNV__IDENTICAL for _ in tmp1[1::2]]\n",
    "IDX__TABLES += tmp1\n",
    "TYPE_OF_CNV += tmp2\n",
    "\n",
    "Lc = len(content)-1\n",
    "if IDX__TABLES[-1] < Lc: \n",
    "    IDX__TABLES.append(Lc)\n",
    "    TYPE_OF_CNV.append(ID__CNV__IDENTICAL)\n",
    "\n",
    "LATEX_TABLES = []\n",
    "for i in range(int(len(tmp1)/2)):\n",
    "    LATEX_TABLES.append(convert__tables(content[tmp1[2*i]:tmp1[2*i+1]]))\n",
    "\n",
    "\n",
    "# for i, L in enum(content):\n",
    "\n",
    "#     for idx_table in IDX__TABLES:\n",
    "#         LATEX_TABLES.append(convert__tables(content[idx_table[0]:idx_table[1]]))\n",
    "content = symbol_replacement(content, PARS)   \n",
    "content = simple_stylistic_replacements(content, type=ID__STYLE__BOLD)\n",
    "content = simple_stylistic_replacements(content, type=ID__STYLE__HIGHLIGHTER)\n",
    "content = simple_stylistic_replacements(content, type=ID__STYLE__ITALIC)\n",
    "\n",
    "content = code_block_converter(content)\n",
    "\n",
    "# Replace \"%\" with \"\\%\" (after having replaced obsidian comments of course)\n",
    "content = [x.replace(\"%\", \"\\%\") for x in content]\n",
    "\n",
    "\n",
    "if PARS['âš™']['EMBEDDED REFERENCES']['convert_non_embedded_references']:\n",
    "    content = non_embedded_references_converter(content, PARS['âš™']['EMBEDDED REFERENCES'])\n",
    "\n",
    "LATEX = []\n",
    "i0 = IDX__TABLES[0]\n",
    "i_tables = 0\n",
    "for j, i in enum(IDX__TABLES[1:]):\n",
    "    if TYPE_OF_CNV[j] == ID__CNV__IDENTICAL:\n",
    "        LATEX += content[i0:i]\n",
    "    elif TYPE_OF_CNV[j] == ID__CNV__TABLE_STARTED:\n",
    "        LATEX += LATEX_TABLES[i_tables]\n",
    "        i_tables += 1\n",
    "    \n",
    "    i0 = i\n",
    "    \n",
    "LATEX = replace_hyperlinks(LATEX)\n",
    "\n",
    "\n",
    "# get text before section, so that it is added after the title, before the table of contents\n",
    "text_before_first_section = ''\n",
    "\n",
    "for i, s in enum(content):\n",
    "    if s.startswith('\\\\section'):\n",
    "        line_first_section = i\n",
    "        break\n",
    "\n",
    "if PARS['âš™']['paragraph']['if_text_before_first_section___place_before_table_of_contents']:\n",
    "    if len(sections)>0:\n",
    "        text_before_first_section = '\\n\\n'.join([s for s in content[:line_first_section] if len(s)>0])\n",
    "        content = content[line_first_section:]\n",
    "\n",
    "#\n",
    "\n",
    "title = path_file.split('\\\\')[-1]\n",
    "\n",
    "PREAMBLE = ['\\documentclass{article}'] +\\\n",
    "           package_loader() +\\\n",
    "           ['\\n'] + ['\\sethlcolor{yellow}'] + ['\\n'] + ['\\n'*2] +\\\n",
    "           ['\\setcounter{secnumdepth}{4}'] +\\\n",
    "           ['\\setlength{\\parskip}{7pt} % paragraph spacing'] +\\\n",
    "           ['\\let\\oldmarginpar\\marginpar'] +\\\n",
    "           ['\\\\renewcommand\\marginpar[1]{\\oldmarginpar{\\\\tiny #1}} % Change \"small\" to your desired font size]'] +\\\n",
    "           ['\\\\begin{document}']+\\\n",
    "           ['\\date{}']+\\\n",
    "           ['\\\\author{Marios Gkionis}']+\\\n",
    "           ['\\\\title{'+ title +'}\\n\\maketitle'\t]+\\\n",
    "           [text_before_first_section]+\\\n",
    "           ['\\\\tableofcontents \\n \\\\newpage']\n",
    "           \n",
    "LATEX = PREAMBLE + LATEX + ['\\\\newpage \\n \\\\bibliographystyle{apacite}']+\\\n",
    "      ['\\\\bibliography{' + PARS['ðŸ“']['bibtex_file_name'] + '}'] + ['\\end{document}']\n",
    "\n",
    "with open(PATHS['tex-file'], 'w', encoding='utf8') as f:\n",
    "    for l in LATEX:\n",
    "        if not l.endswith('\\n'): l+='\\n'\n",
    "        f.write(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugginng"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string: This is a [[p123]] test [[p42]] string [[pabc]] with patterns.\n",
      "Modified string: This is a \\cite{p123} test \\cite{p42} string [[pabc]] with patterns.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_pattern_with_cite(s):\n",
    "    pattern = r'\\[\\[p(\\d+)\\]\\]'  # Updated regular expression pattern with capturing group\n",
    "    replaced_string = re.sub(pattern, r'\\\\cite{p\\1}', s)\n",
    "    return replaced_string\n",
    "\n",
    "# Example string\n",
    "test_string = \"This is a [[p123]] test [[p42]] string [[pabc]] with patterns.\"\n",
    "\n",
    "result_string = replace_pattern_with_cite(test_string)\n",
    "print(\"Original string:\", test_string)\n",
    "print(\"Modified string:\", result_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def retrieve_info(fileName, textFilePath, folderPath):\n",
    "    # Read the text file\n",
    "    with open(textFilePath, 'r', encoding='utf8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Search for the fileName in the lines and retrieve associated paths\n",
    "    matching_paths = [line.strip() for line in lines if line.startswith(fileName+\":\")]\n",
    "\n",
    "    if matching_paths:\n",
    "        # Process retrieved paths\n",
    "        for path_line in matching_paths:\n",
    "            path = path_line.split(': ')[1].strip()\n",
    "            if not os.path.exists(path):\n",
    "                new_path = get_embedded_reference_path(fileName + '.md', PARS, search_in='vault')\n",
    "                if new_path:\n",
    "                    updated_line = f\"{fileName}: {new_path}\\n\"\n",
    "                    lines[lines.index(path_line+'\\n')] = updated_line\n",
    "                    with open(textFilePath, 'w', encoding='utf-8') as file:\n",
    "                        file.writelines(lines)\n",
    "                    # print(f\"Updated path for '{fileName}' in the text file.\")\n",
    "                else:\n",
    "                    raise Exception(f\"Path '{path}' not found. Also, unable to find an alternative path for '{fileName}'.\")\n",
    "\n",
    "    else:\n",
    "        path_found = get_embedded_reference_path(fileName + '.md', PARS, search_in='vault')\n",
    "        if path_found:\n",
    "            with open(textFilePath, 'a', encoding='utf-8') as file:\n",
    "                file.write(f\"{fileName}: {path_found}\\n\")\n",
    "            # print(f\"Path for '{fileName}' appended as a new line in the text file.\")\n",
    "        else:\n",
    "            raise Exception(f\"No information found for '{fileName}' in the provided text file and unable to find an alternative path.\")\n",
    "\n",
    "# Example usage:\n",
    "fileName_input = \"p538--1\"\n",
    "textFilePath_input = path_list_note_paths\n",
    "folderPath_input = path_files\n",
    "\n",
    "retrieve_info(fileName_input, textFilePath_input, folderPath_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars = '\\w' + SPECIAL_CHARACTERS + '\\[\\]'\n",
    "\n",
    "pattern = r\"\\[([^\\]]+)\\]\"\n",
    "regexMdLinks = '/\\[([^\\[]+)\\](\\(.*\\))'\n",
    "s = '[some example]' \n",
    "s = '[Could not install packages due to an OSError: WinError 5 Access is denied](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "match = re.findall(regexMdLinks, s)\n",
    "match\n",
    "\n",
    "\n",
    "# pattern = r\"\\[([^\\]]+)\\]\\(([^\\)]+)\\)\"\n",
    "\n",
    "# pattern = r\"\\[([^\\]]+)\\]\\(([^\\)]+)\\)\"\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "\n",
    "\n",
    "# s = 'example with [linking a website](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "\n",
    "# match = re.findall(pattern, s)\n",
    "# match\n",
    "\n",
    "# import re\n",
    "\n",
    "# pattern = r\"\\[([^\\[\\]]+)\\]\\(([^\\(\\)]+)\\)\"\n",
    "\n",
    "# text = r\"[some sentence with [brackets] or (parentheses) inside it](some website)\"\n",
    "\n",
    "# match = re.findall(pattern, text)\n",
    "# match\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Could not install packages due to an OSError: WinError 5 Access is denied', 'https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied')\n",
      "\\href{https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied}{Could not install packages due to an OSError: WinError 5 Access is denied}\n"
     ]
    }
   ],
   "source": [
    "# Anything that isn't a square closing bracket\n",
    "name_regex = \"[^]]+\"\n",
    "# http:// or https:// followed by anything but a closing paren\n",
    "url_regex = \"http[s]?://[^)]+\"\n",
    "text = '[Could not install packages due to an OSError: WinError 5 Access is denied](https://stackoverflow.com/questions/73339138/could-not-install-packages-due-to-an-oserror-winerror-5-access-is-denied)' \n",
    "\n",
    "markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "\n",
    "\n",
    "for match in re.findall(markup_regex, text):\n",
    "    print(match)\n",
    "    markdown_link = '[' + match[0] + '](' + match[1] + ')'\n",
    "    latex_link = \"\\\\href{\" + match[1] + \"}{\" + match[0] + \"}\"\n",
    "    print(text.replace(markdown_link, latex_link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First line is gooooood',\n",
       " 'Second line has ',\n",
       " 'Third line has  comments ',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_markdown_comments(S):\n",
    "    result = []\n",
    "    in_comment = False\n",
    "    for line in S:\n",
    "        comment_start = line.find(\"%%\")\n",
    "        while comment_start != -1:\n",
    "            comment_end = line.find(\"%%\", comment_start + 2)\n",
    "            if comment_end == -1:\n",
    "                line = line[:comment_start]\n",
    "                in_comment = True\n",
    "                break\n",
    "            else:\n",
    "                line = line[:comment_start] + line[comment_end + 2:]\n",
    "                comment_start = line.find(\"%%\")\n",
    "        if in_comment:\n",
    "            comment_end = line.find(\"%%\")\n",
    "            if comment_end != -1:\n",
    "                line = line[comment_end + 2:]\n",
    "                in_comment = False\n",
    "            else:\n",
    "                line = \"\"\n",
    "        result.append(line)\n",
    "    return result\n",
    "\n",
    "\n",
    "S = [\n",
    "    'First line is gooooood',\n",
    "    'Second line has %%comment%%',\n",
    "    'Third line has %% two %% comments %% yall%%',\n",
    "    'Fourth line has %% starting comment',\n",
    "    'which %% ends in fifth %% but starts again %%'\n",
    "]\n",
    "\n",
    "# ['First line is gooooood', 'Second line has ', 'Third line has  comments ', 'Fourth line has %% starting comment', ' ends in fifth ']\n",
    "remove_markdown_comments(S)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal links/crossrefs\n",
    "\n",
    "Using this format:\n",
    "\n",
    "\\section{Hello World}\n",
    "\\label{sec:hello}\n",
    "\n",
    "\n",
    "\\hyperref[sec:hello]{Word of text}\n",
    "\n",
    "\n",
    "### Strategy\n",
    "1. Add the label with the same name as in the Obsidian note. Add it just using \"\\n \\label{sec:label}\" instead of creating a new line\n",
    "2. Map the sections and blocks so that we can correspond them easily\n",
    "\n",
    "\n",
    "\n",
    "## Limitations\n",
    "\n",
    "### Hyperlinks\n",
    "- The pattern does not take account for the cases wherein there's more brackets inside the brackets\n",
    "\n",
    "\n",
    "### Cannot understand Windows emojis\n",
    "\n",
    "--> Use [this list of symbols](https://milde.users.sourceforge.net/LUCR/Math/mathpackages/amssymb-symbols.pdf) instead and the `\\usepackage{amssymb}` command\n",
    "\n",
    "\n",
    "\n",
    "## Programming mistakes/weaknesses in the code\n",
    "1. Redundant replacement in: \"âš WARNING--1\" (search for it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa67766ae418968f0c59ac0eb4df618cb98e2442e22a4762b28c70784bead217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
